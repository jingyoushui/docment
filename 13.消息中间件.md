#  什么是消息中间件？ 

##  消息中间件(MQ)的定义 

其实并没有标准定义。一般认为，消息中间件属于分布式系统中一个子系统，关注于数据的发送和接收，利用高效可靠的异步消息传递机制对分布式系统中的其余各个子系统进行集成。 

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsPf4tKw.jpg) 

##  为什么要用消息中间件？ 

假设一个电商交易的场景，用户下单之后调用库存系统减库存，然后需要调用物流系统进行发货，如果交易、库存、物流是属于一个系统的，那么就是接口调用。但是随着系统的发展，各个模块越来越庞大、业务逻辑越来越复杂，必然是要做服务化和业务拆分的。这个时候就需要考虑这些系统之间如何交互，第一反应就是RPC（Remote Procedure Call）。系统继续发展，可能一笔交易后续需要调用几十个接口来执行业务，比如还有风控系统、短信服务等等。这个时候就需要消息中间件登场来解决问题了。

所以消息中间件主要解决分布式系统之间消息的传递，同时为分布式系统中其他子系统提供了伸缩性和扩展性。为系统带来了：

低耦合，不管是程序还是模块之间，使用消息中间件进行间接通信。

异步通信能力，使得子系统之间得以充分执行自己的逻辑而无需等待。

缓冲能力，消息中间件像是一个巨大的蓄水池，将高峰期大量的请求存储下来慢慢交给后台进行处理，对于秒杀业务来说尤为重要。

名称解释：

 *伸缩性\** *，是指通过不断向集群中加入服务器的手段来缓解不断上升的用户并发访问压力和不断增长的数据存储需求。就像弹簧一样挂东西一样，用户多，伸一点，用户少，浅一点，啊，不对，缩一点。是伸缩，不是深浅。衡量架构是否高伸缩性的主要标准就是是否可用多台服务器构建集群，是否容易向集群中添加新的服务器。加入新的服务器后是否可以提供和原来服务器无差别的服务。集群中可容纳的总的服务器数量是否有限制。**

 *扩展性\** *，主要标准就是在网站增加新的业务产品时，是否可以实现对现有产品透明无影响，不需要任何改动或者很少改动既有业务功能就可以上线新产品。比如用户购买电影票的应用，现在我们要增加一个功能，用户买了铁血战士的票后，随机抽取用户送异形的限量周边。怎么做到不改动用户购票功能的基础上增加这个功能。熟悉设计模式的同学，应该很眼熟，这是设计模式中的开闭原则（对扩展开放，对修改关闭）在架构层面的一个原则。**

##  和RPC有何区别？ 

RPC和消息中间件的场景的差异很大程度上在于就是“依赖性”和“同步性”。

比如短信通知服务并不是事交易环节必须的，并不影响下单流程，不是强依赖，所以交易系统不应该依赖短信服务。比如一些数据分析程序可能需要在拿到一天的总销售量，这个就只需要销售中心提供接口在需要时调用即可。

消息中间件出现以后对于交易场景可能是调用库存中心等强依赖系统执行业务，之后发布一条消息（这条消息存储于消息中间件中）。像是短信通知服务、数据统计服务等等都是依赖于消息中间件去消费这条消息来完成自己的业务逻辑。

RPC方式是典型的同步方式，让远程调用像本地调用。消息中间件方式属于异步方式。消息队列是系统级、模块级的通信。RPC是对象级、函数级通信。

 相同点： 都是分布式下面的通信方式。

##  消息中间件有些什么使用场景？ 

###  异步处理 

场景说明：用户注册后，需要发注册邮件和注册短信。传统的做法有两种1.串行的方式；2.并行方式。

串行方式：将注册信息写入数据库成功后，发送注册邮件，再发送注册短信。以上三个任务全部完成后，返回给客户端。

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsVXVlks.jpg) 

（2）并行方式：将注册信息写入数据库成功后，发送注册邮件的同时，发送注册短信。以上三个任务完成后，返回给客户端。与串行的差别是，并行的方式可以提高处理的时间。

假设三个业务节点每个使用50毫秒钟，不考虑网络等其他开销，则串行方式的时间是150毫秒，并行的时间可能是100毫秒。

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsPoZeUn.jpg) 

小结：如以上案例描述，传统的方式系统的性能（并发量，吞吐量，响应时间）会有瓶颈。如何解决这个问题呢？

引入消息队列，将不是必须的业务逻辑，异步处理。

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpszj98tj.jpg) 

按照以上约定，用户的响应时间相当于是注册信息写入数据库的时间，也就是50毫秒。注册邮件，发送短信写入消息队列后，直接返回，因此写入消息队列的速度很快，基本可以忽略，因此用户的响应时间可能是50毫秒。因此架构改变后，系统的吞吐量提高到每秒20 QPS。比串行提高了3倍，比并行提高了两倍。

###  应用解耦 

场景说明：用户下单后，订单系统需要通知库存系统。传统的做法是，订单系统调用库存系统的接口。

传统模式的缺点：

1）  假如库存系统无法访问，则订单减库存将失败，从而导致订单失败；

2）  订单系统与库存系统耦合；

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsXAA43e.jpg) 

如何解决以上问题呢？引入应用消息队列后的方案

订单系统：用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功。

库存系统：订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作。

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsVOH1Da.jpg) 

假如：在下单时库存系统不能正常使用。也不影响正常下单，因为下单后，订单系统写入消息队列就不再关心其他的后续操作了。实现订单系统与库存系统的应用解耦。

###  流量削峰 

流量削峰也是消息队列中的常用场景，一般在秒杀或团抢活动中使用广泛。

应用场景：秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。为解决这个问题，一般需要在应用前端加入消息队列：可以控制活动的人数；可以缓解短时间内高流量压垮应用。

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsvkQZd6.jpg) 

用户的请求，服务器接收后，首先写入消息队列。假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面；秒杀业务根据消息队列中的请求信息，再做后续处理。

###  日志处理 

日志处理是指将消息队列用在日志处理中，比如Kafka的应用，解决大量日志传输的问题。架构简化如下：

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsp14YN1.jpg) 

日志采集客户端，负责日志数据采集，定时写入Kafka队列：Kafka消息队列，负责日志数据的接收，存储和转发；日志处理应用：订阅并消费kafka队列中的日志数据；

###  消息通讯 

消息通讯是指，消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列，或者聊天室等。

点对点通讯：客户端A和客户端B使用同一队列，进行消息通讯。

聊天室通讯：客户端A，客户端B，客户端N订阅同一主题，进行消息发布和接收。实现类似聊天室效果。

##  消息中间件的编年史  

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsnoBZnX.jpg) 

卡夫卡与法国作家马塞尔·普鲁斯特，爱尔兰作家詹姆斯·乔伊斯并称为西方现代主义文学的先驱和大师。《变形记》是卡夫卡的短篇代表作，是卡夫卡的艺术成就中的一座高峰，被认为是20世纪最伟大的小说作品之一。

##  常见的消息中间件比较  

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpshJj1XS.jpg) 

如果一般的业务系统要引入MQ，怎么选型：

用户访问量在ActiveMQ的可承受范围内，而且确实主要是基于解耦和异步来用的，可以考虑ActiveMQ，也比较贴近Java工程师的使用习惯。 

RabbitMQ，但是确实erlang语言阻止了我们去深入研究和掌控，对公司而言，几乎处于不可控的状态，但是确实是开源的，有比较稳定的支持，活跃度也高。

对自己公司技术实力有绝对自信的，可以用RocketMQ 。

所以中小型公司，技术实力较为一般，技术挑战不是特别高，用ActiveMQ、RabbitMQ是不错的选择；大型公司，基础架构研发实力较强，用RocketMQ是很好的选择

如果是大数据领域的实时计算、日志采集等场景，用Kafka是业内标准的，绝对没问题，社区活跃度很高，几乎是全世界这个领域的事实性规范。

 

#  JMS和ActiveMQ  

JMS（Java Messaging Service）是Java平台上有关面向消息中间件的技术规范，实际上是一套api，它便于消息系统中的Java应用程序进行消息交换,并且通过提供标准的产生、发送、接收消息的接口简化企业应用的开发，ActiveMQ而是这个规范的一个具体实现。

##  JMS规范 

###  JMS  对象模型 

1）连接工厂。连接工厂负责创建一个JMS连接。

2）JMS连接。JMS连接（Connection）表示JMS客户端和服务器端之间的一个活动的连接，是由客户端通过调用连接工厂的方法建立的。

3）JMS会话。JMS会话（Session）表示JMS客户与JMS服务器之间的会话状态。JMS会话建立在JMS连接上，表示客户与服务器之间的一个会话线程。

4）JMS目的/ Broker。客户用来指定它生产的消息的目标和它消费的消息的来源的对象，一个消息中间件的实例。

5）JMS生产者和消费者。生产者（Message Producer）和消费者（Message Consumer）对象由Session对象创建，用于发送和接收消息。

消息的消费可以采用以下两种方法之一：

· 同步消费。通过调用 消费者的receive 方法从目的地中显式提取消息。receive 方法可以一直阻塞到消息到达。

· 异步消费。客户可以为消费者注册一个消息监听器，以定义在消息到达时所采取的动作。

###  JMS规范中的消息 

JMS 消息由以下三部分组成：

· 消息头。每个消息头字段都有相应的getter 和setter 方法。

· 消息属性。如果需要除消息头字段以外的值，那么可以使用消息属性。

· 消息体。JMS 定义的消息类型有TextMessage、MapMessage、BytesMessage、

StreamMessage 和 ObjectMessage。ActiveMQ也有对应的实现。

 

###  JMS消息模型 

####  *Point-to-Point(P2P)  / 点对点 

消息通过称为队列的一个虚拟通道来进行交换。队列是生产者发送消息的目的地和接受者消费消息的消息源。

每条消息通仅会传送给一个接受者。可能会有多个接受者在一个队列中侦听，但是每个队列中的消息只能被队列中的一个接受者消费。

消息存在先后顺序。一个队列会按照消息服务器将消息放入队列中的顺序，把它们传送给消费者当消息已被消费时，就会从队列头部将它们删除。

每个消息只有一个消费者（Consumer）(即一旦被消费，消息就不再在消息队列中)

发送者发送了消息之后，不管接收者有没有正在运行，它不会影响到消息被发送到队列

接收者在成功接收消息之后需向队列应答成功

如果希望发送的每个消息都应该被成功处理的话，使用这个P2P模式。

####  *Topic/ 主题（发布订阅(Pub/Sub) ） 

1、消息生产者（发布）将消息发布到topic中，同时有多个消息消费者（订阅）消费该消息。和点对点方式不同，发布到topic的消息会被所有订阅者消费。

3、如果你希望发送的消息可以不被做任何处理、或者被一个消息者处理、或者可以被多个消费者处理的话，那么可以采用topic模型 

##  ActiveMQ 

###  ActiveMQ安装、部署和运行  

下载 Windows版 ActiveMQ，解压，运行bin目录下的activemq.bat即可。Linux下操作类似（进入bin目录运行./activemq start启动，./activemq stop关闭）。

下载地址：http://activemq.apache.org/activemq-580-release.html

运行后在浏览器中访问http://127.0.0.1:8161/admin，即可看到ActiveMQ的管理控制台

ActiveMQ中，61616为服务端口，8161为管理控制台端口。

###  使用ActiveMQ  

####  *原生API 

Maven配置

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsv4x7xO.jpg) 

connection.createSession参数解释：

第一个参数是否使用事务:当消息发送者向消息提供者（即消息代理）发送消息时，消息发送者等待消息代理的确认，没有回应则抛出异常，消息发送程序负责处理这个错误。

第二个参数消息的确认模式：

AUTO_ACKNOWLEDGE ： 指定消息接收者在每次收到消息时自动发送确认。消息只向目标发送一次，但传输过程中可能因为错误而丢失消息。

CLIENT_ACKNOWLEDGE ： 由消息接收者确认收到消息，通过调用消息的acknowledge()方法（会通知消息提供者收到了消息）

DUPS_OK_ACKNOWLEDGE ： 指定消息提供者在消息接收者没有确认发送时重新发送消息（这种确认模式不在乎接收者收到重复的消息）。

##### 消费者的接收方式：同步和异步

```
 **topic模式如果没有消费者，消息会丢失，queue模式的会保存消息**
```



<table><tr><td bgcolor=#FF00FF>背景色的设置是按照十六进制颜色值：#7FFFD4</td></tr></table>

####  *和Spring的结合 

1、增加Maven配置

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wps3Saf8J.jpg) 

2、生产者在spring的配置中增加ActiveMQ相关配置，包括命名空间

3、生产者在代码中编写发送逻辑，可以topic模式，也可queue模式

4、消费者在spring的配置中增加ActiveMQ相关配置，包括命名空间

5、消费者在代码中编写接收逻辑，可以topic模式，也可queue模式

详情见代码，模块名，生产者：with-spring，消费者：with-spring-consumer

####  *和Springboot的结合 

和Spring基本没什么差别，参见reply包下的代码。运行测试程序，在测试目录test下。

###  ActiveMQ实战之一   用户注册的异步处理 

参见模块asyncApp，注意观察：

1、 串行实现

2、 并行实现

3、 使用MQ进行实现

4、 给MQ实现，增加短信服务的校验码应答给生产者处理

5、 系统扩展，需要给数据中心和客户服务也发送消息

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/4943997-286cfaa695cbec0d.webp)

###  ActiveMQ高级特性和用法 

####  *嵌入式ActiveMQ 

在自己的应用程序中嵌入一个消息队列。见代码模块 no-spring包embed下。

####  *消息存储的持久化 

ActiveMQ的另一个问题就是只要是软件就有可能挂掉，挂掉不可怕，怕的是挂掉之后把信息给丢了，怎么办，可以进行消息的持久化，ActiveMQ提供了几种持久化方式：

\1. AMQ消息存储-基于文件的存储方式，它具有写入速度快和容易恢复的特点。消息存储在一个个文件中，文件的默认大小为32M，如果一条消息的大小超过了32M，那么这个值必须设置大一点。当一个存储文件中的消息已经全部被消费，那么这个文件将被标识为可删除，在下一个清除阶段，这个文件被删除。AMQ适用于ActiveMQ5.3之前的版本。

\2. KahaDB消息存储-提供了容量的提升和恢复能力，是现在的默认存储方式；KahaDB是基于文件的本地数据库储存形式，虽然没有AMQ的速度快，但是它具有强扩展性，恢复的时间比AMQ短，从5.4版本之后KahaDB做为默认的持久化方式。

\3. JDBC消息存储-消息基于JDBC存储的；

\4. Memory消息存储-基于内存的消息存储，由于内存不属于持久化范畴。所以内存存储不在讨论范围内。

##### KahaDB

由于KahaDB是默认的持久化存储方案。所以即使你不配置任何的KahaDB参数信息，ActiveMQ也会启动KahaDB。这种情况下，KahaDB文件所在位置是你的ActiveMQ安装路径下的/data/KahaDB子目录。

##### 关系型数据库存储方案

从ActiveMQ 4+版本开始，ActiveMQ就支持使用关系型数据库进行持久化存储——通过JDBC实现的数据库连接。可以使用的关系型数据库囊括了目前市面的主流数据库。

使用JDBC的方式持久化

1、修改配置文件conf/activemq.xml：

将其中的这段配置：

<persistenceAdapter>

​	<kahaDB directory="${activemq.base}/data/kahadb"/>

</persistenceAdapter>

修改为为：

<persistenceAdapter>

​    <jdbcPersistenceAdapter  dataSource="#mysql-ds "/>

</persistenceAdapter>

2、然后在</ broker >标签后，增加数据源的配置：

  <bean id="mysql-ds" class="org.apache.commons.dbcp2.BasicDataSource" destroy-method="close">

​    <property name="driverClassName" value="com.mysql.jdbc.Driver"/>

​    <property name="url" value="jdbc:mysql://localhost:3306/activemq?relaxAutoCommit=true&useUnicode=true&characterEncoding=utf-8&serverTimezone=UTC"/>

​    <property name="username" value="root"/>

​    <property name="password" value="123456"/>

​    <property name="poolPreparedStatements" value="true"/>

  </bean>

其中 ?relaxAutoCommit=true 必须有，其他的属性根据数据库的配置自行决定。

3、将mysql-connector-java-5.1.34-bin.jar（版本可以自行选择）放到ActiveMQ的/ lib目录下。

4、在Mysql数据库中增加在连接字符串中设置的数据库名activemq

5、运行后，会发现在库中增加了3个表

 activemq_acks： 用于存储订阅关系。如果是持久化Topic，订阅者和服务器的订阅关系在这个表保存，主要数据库字段如下：

container：消息的destination

sub_dest：如果是使用static集群，这个字段会有集群其他系统的信息

client_id：每个订阅者都必须有一个唯一的客户端id用以区分

sub_name：订阅者名称

selector：选择器，可以选择只消费满足条件的消息。条件可以用自定义属性实现，可支持多属性and和or操作

last_acked_id：记录消费过的消息的id

 activemq_lock： 在集群环境中才有用，只有一个Broker可以获得消息，称为Master Broker，其他的只能作为备份等待Master Broker不可用，才可能成为下一个Master Broker。这个表用于记录哪个Broker是当前的Master Broker。

 activemq_msgs： 用于存储消息，Queue和Topic都存储在这个表中。主要的数据库字段如下：

id：自增的数据库主键

container：消息的destination

msgid_prod：消息发送者客户端的主键

msg_seq：是发送消息的顺序，msgid_prod+msg_seq可以组成jms的messageid

expiration：消息的过期时间，存储的是从1970-01-01到现在的毫秒数

msg：消息本体的java序列化对象的二进制数据

priority：优先级，从0-9，数值越大优先级越高

####  *消息的持久化订阅 

分别运行订阅模式和P2P模式，可以发现，P2P模式缺省把消息进行持久化，而topic模式是没有的。

##### 一般topic模式实验：

1、 启动两个消费者，启动一个生产者，发送消息，两个消费者都可以收到。

2、 关闭一个消费者，生产者发送消息，活跃的消费者可以收到消息，启动被关闭的消费者，无法收到消息。

3、 关闭所有消费者，生产者发送消息，在ActiveMQ控制台可以看见消息已被接收，关闭再启动ActiveMQ，启动消费者收不到消息。

如果topic模式下，需要消费者在离线又上线后，不管ActiveMQ是否重启过，都保证可以接受到消息，就需要进行持久化订阅。具体代码参见模块no-spirng包durabletopic。

##### 持久Topic消费者端

需要设置客户端id：**connection**.setClientID( "Mark" );

消息的destination变为 Topic 

消费者类型变为TopicSubscriber

消费者创建时变为session.createDurableSubscriber(destination,"任意名字，代表订阅名 ");

运行一次消费者，将消费者在ActiveMQ上进行一次注册。然后在ActiveMQ的管理控制台subscribers页面可以看见我们的消费者。

 效果： 

1、 运行生产者，发布消息，多个消费者可以正常收到。

2、 关闭一个消费者，运行生产者，发布消息后再启动被关闭的消费者，可以收到离线后的消息；

3、 关闭所有消费者，运行生产者，发布消息后，关闭ActiveMQ再启动，启动所有消费者，都可以收到消息。

 注意：生产者端无需另外单独配置 

##### 消息非持久化

修改messageProducer.setDeliveryMode(DeliveryMode.NON_PERSISTENT);来设置消息本身的持久化属性为非持久化。重复上述实验，可以发现，第1,2点保持不变，但是第三点，当关闭ActiveMQ再启动，消费者关闭后再启动，是收不到消息的。

说明，即使进行了持久订阅，但是消息本身如果是不持久化的，ActiveMQ关闭再启动，这些非持久化的消息会丢失，进行持久订阅的消费者也是收不到自身离线期间的消息的。

####  *消息的可靠性 

消息发送成功后，接收端接收到了消息。然后进行处理，但是可能由于某种原因，高并发也好，IO阻塞也好，反正这条消息在接收端处理失败了。而点对点的特性是一条消息，只会被一个接收端给接收，只要接收端A接收成功了，接收端B，就不可能接收到这条消息，如果是一些普通的消息还好，但是如果是一些很重要的消息，比如说用户的支付订单，用户的退款，这些与金钱相关的，是必须保证成功的，那么这个时候要怎么处理呢？必须要保证消息的可靠性，除了消息的持久化，还包括两个方面，一是生产者发送的消息可以被ActiveMQ收到，二是消费者收到了ActiveMQ发送的消息。

##### 生产者

###### **send方法**

在生产者端，我们会使用send() 方法向ActiveMQ发送消息，默认情况下，持久化消息以同步方式发送，send() 方法会被阻塞，直到 broker 发送一个确认消息给生产者，这个确认消息表示broker已经成功接收到消息，并且持久化消息已经把消息保存到二级存储中。

 实验send()方法 ：在模块no-spring包msgreliability下的JmsMsgReliablitySendProducer中send方法上打一个断点，可以看到send方法每执行一次，ActiveMQ管理控制台增加一条入队消息，数据库中增加一条消息。

###### **事务消息**

事务中消息（无论是否持久化），会进行异步发送，send() 方法不会被阻塞。但是commit 方法会被阻塞，直到收到确认消息，表示broker已经成功接收到消息，并且持久化消息已经把消息保存到二级存储中。

 实验事务消息 ：在模块no-spring包msgreliability下的JmsMsgReliablityTranProducer中在**session**.commit()打一个断点，可以看到send方法每执行一次，ActiveMQ管理控制台和数据库中没有任何变化，只有执行完**session**.commit()后ActiveMQ管理控制台和数据库中才增加。

###### **总结**

非持久化又不在事务中的消息，可能会有消息的丢失。为保证消息可以被ActiveMQ收到，我们应该采用事务消息或持久化消息。

##### 消费者

对消息的确认有4种机制

1、 AUTO_ACKNOWLEDGE = 1   自动确认

2、 CLIENT_ACKNOWLEDGE = 2   客户端手动确认  

3、 DUPS_OK_ACKNOWLEDGE = 3   自动批量确认

4、 SESSION_TRANSACTED = 0   事务提交并确认

ACK_MODE描述了Consumer与broker确认消息的方式(时机),比如当消息被Consumer接收之后,Consumer将在何时确认消息。所以ack_mode描述的不是producer于broker之间的关系，而是customer于broker之间的关系。

对于broker而言，只有接收到ACK指令,才会认为消息被正确的接收或者处理成功了,通过ACK，可以在consumer与Broker之间建立一种简单的“担保”机制.

session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);

第一个参数:是否支持事务，如果为true，则会忽略第二个参数，自动被jms服务器设置为SESSION_TRANSACTED

###### **AUTO_ACKNOWLEDGE**  

自动确认

  “同步”(receive)方法返回message给消息时会立即确认。

   在"异步"(messageListener)方式中,将会首先调用listener.onMessage(message)，如果onMessage方法正常结束,消息将会正常确认。如果onMessage方法异常，将导致消费者要求ActiveMQ重发消息。此外需要注意，消息的重发次数是有限制的，每条消息中都会包含“redeliveryCounter”计数器，用来表示此消息已经被重发的次数，如果重发次数达到阀值，将导致broker端认为此消息无法消费,此消息将会被删除或者迁移到"dead letter"通道中。

   因此当我们使用messageListener方式消费消息时，可以在onMessage方法中使用try-catch,这样可以在处理消息出错时记录一些信息，而不是让consumer不断去重发消息；如果你没有使用try-catch,就有可能会因为异常而导致消息重复接收的问题,需要注意onMessage方法中逻辑是否能够兼容对重复消息的判断。

 实验方法 ：在模块no-spring包msgreliability下的JmsMsgReliablityConsumerAsyn中onMessage方法中增加一条throw语句，出现消息重发的现象。

###### **CLIENT_ACKNOWLEDGE :** 

客户端手动确认，这就意味着AcitveMQ将不会“自作主张”的为你ACK任何消息，开发者需要自己择机确认。可以用方法： message.acknowledge()，或session.acknowledge()；效果一样。

如果忘记调用acknowledge方法，将会导致当consumer重启后，会接受到重复消息，因为对于broker而言，那些尚未真正ACK的消息被视为“未消费”。

我们可以在当前消息处理成功之后，立即调用message.acknowledge()方法来"逐个"确认消息，这样可以尽可能的减少因网络故障而导致消息重发的个数；当然也可以处理多条消息之后，间歇性的调用acknowledge方法来一次确认多条消息，减少ack的次数来提升consumer的效率，不过需要自行权衡。

 实验方法 ：在模块no-spring包msgreliability下的JmsMsgReliablityConsumerAsyn中将session模式改为Session. *CLIENT_ACKNOWLEDGE\** **\**，， 启动两个消费者，发送消息后，可以看到JmsMsgReliablityConsumerAsyn接收了消息但不确认。当JmsMsgReliablityConsumerAsyn重新启动后，会再一次收到同样的消息。加入 *message.acknowledge() 后该现象消失。

###### **DUPS_OK_ACKNOWLEDGE**

类似于AUTO_ACK确认机制，为自动批量确认而生，而且具有“延迟”确认的特点，ActiveMQ会根据内部算法，在收到一定数量的消息自动进行确认。在此模式下，可能会出现重复消息，什么时候？当consumer故障重启后，那些尚未ACK的消息会重新发送过来。

###### **SESSION_TRANSACTED**

当session使用事务时，就是使用此模式。当决定事务中的消息可以确认时，必须调用session.commit()方法，commit方法将会导致当前session的事务中所有消息立即被确认。在事务开始之后的任何时机调用rollback()，意味着当前事务的结束，事务中所有的消息都将被重发。当然在commit之前抛出异常，也会导致事务的rollback。

####  *通配符式订阅 

Wildcards 用来支持联合的名字分层体系（federated name hierarchies）。它不是JMS 规范的一部分，而是ActiveMQ 的扩展。ActiveMQ 支持以下三种

wildcards：

· "." 用于作为路径上名字间的分隔符。

· "*" 用于匹配路径上的任何名字。

· ">" 用于递归地匹配任何以这个名字开始的destination。

订阅者可以明确地指定destination 的名字来订阅消息，或者它也可以使用wildcards 来定义一个分层的模式来匹配它希望订阅的 destination。

具体情况参见代码，在模块no-spirng包wildcards下。

####  *死信队列 

用来保存处理失败或者过期的消息。 

出现下面情况时，消息会被重发： 

i. 事务会话被回滚。

ii. 事务会话在提交之前关闭。

iii. 会话使用CLIENT_ACKNOWLEDGE模式，并且Session.recover()被调用。 

iv. 自动应答失败

当一个消息被重发超过最大重发次数（缺省为6次，消费者端可以修改）时，会给broker发送一个"有毒标记“，这个消息被认为是有问题，这时broker将这个消息发送到死信队列，以便后续处理。 

在配置文件(activemq.xml)来调整死信发送策略。

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsnodxIF.jpg) 

可以单独使用死信消费者处理这些死信。参见代码，在模块no-spirng包dlq下。

 注意 ，该代码中展示了如何配置重发策略。同时，重试策略属于ActiveMQ的部分，所以有部分connectionFactory，connection的声明等等不能使用接口，必须使用ActiveMQ的实现。

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpslFEQiB.jpg) 

####  *Mirrored Queue 镜像队列\** **\**(了解即可) 

ActiveMQ每一个queue中消息只能被一个消费者消费，然而，有时候，你希望能够监视生产者和消费者之间的消息流。

MirroredQueue: Broker会把发送到某一个队列上的所有消息转发到一个名称类似的topic,因此监控程序只需要订阅这个topic.为启用MirroredQueue，首先要将BrokerService的useMirroredQueues属性设置为true：

<broker xmlns=http://activemq.apache.org/schema/core useMirroredQueue="true"></broker>

 然后可以通过destinationInterceptors设置其属性，如mirrortopic的前缀，缺省是VritualTopic.Mirror.

修改后缀的配置示例：

<broker xmlns="http://activemq.apache.org/schema/core">    <destinationInterceptors>       <mirroredQueue copyMessage="true" postfix=".qmirror" prefix="" />    </destinationInterceptors></broker>

 

####  *消费者集群下需要考虑的问题 

我们现实中往往有这样的需求：

\1. 消息接收方和发送方都是集群。 

\2. 同一个消息的接收方可能有多个集群进行消息的处理。

\3. 不同集群对于同一条消息的处理不能相互干扰。

希望可以达到如下的效果：

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wps132dTw.jpg) 

对于集群消息，采用单独采用queue或者topic都不满足要求。

采用Queue模型导致：单独的queue，消息可能被其他集群消费

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsHBCCts.jpg) 

采用Topic模型导致，采用topic消息可能被同一集群的相同应用重复消费。：

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsD9v23n.jpg) 

##### 解决方案一，级联

将Jms的Topic和Queue进行级联使用

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsJixtEj.jpg) 

缺点，实现方式繁重，需要独立的中转的消息订阅者来完成，多了一次消息的投递和一次消息消费过程，对效率有影响，增加了消息中间件负载压力。

##### 解决方案二

ActiveMQ提供了虚拟主题和组合Destinations都可以达到这个效果。

####  *虚拟\** **\**Destination 

对于消息发布者来说，就是一个正常的Topic，名称以VirtualTopic.开头。例如VirtualTopic.vtgroup

对于消息接收端来说，是个队列，不同应用里使用不同的前缀作为队列的名称，即可表明自己的身份即可实现消费端应用分组。

 例如Consumer.A.VirtualTopic. vtgroup，说明它是名称为A群组的消费端，同理Consumer.B.VirtualTopic. vtgroup说明是一个名称为B群组的客户端。

默认虚拟主题的前缀是 ：VirtualTopic.

 消费虚拟地址默认格式：Consumer.*.VirtualTopic.

参见代码，在模块no-spirng包virtualtopic下

####  *组合\** **\**Destination 

组合队列允许用一个虚拟的destination代表多个destinations。这样就可以通过composite destinations在一个操作中同时向多个destination发送消息。

多个destination之间采用“,”分割。例如：

 Queue queue = new ActiveMQQueue("FOO.A,FOO.B,FOO.C");

 或

 Destination destination = session.createQueue("my-queue,my-queue2");

如果希望使用不同类型的destination，那么需要加上前缀如queue:// 或topic://，例如：

  Queue queue = new ActiveMQQueue("cd.queue,topic://cd.mark");

参见代码，在模块no-spirng包compositedest下

###  ActiveMQ实战之二  限时订单 

####  *轮询数据库会带来什么问题？  

轮询数据库在实现限时订单上是可行的，而且实现起来很简单。写个定时器去每隔一段时间扫描数据库，检查到订单过期了，做适当的业务处理。

但是轮询会带来什么问题？

1、轮询大部分时间其实是在做无用功，我们假设一张订单是45分钟过期，每分钟我们扫描一次，对这张订单来说，要扫描45次以后，才会检查到这张订单过期，这就意味着数据库的资源（连接，IO）被白白浪费了；

2、处理上的不及时，一个待支付的电影票订单我们假设是12:00:35过期，但是上次扫描的时间是12:00:30，那么这个订单实际的过期时间是什么时候？12:01:30，和我本来的过期时间差了55秒钟。放在业务上，会带来什么问题？这张电影票，假设是最后一张，有个人12:00:55来买票，买得到吗？当然买不到了。那么这张电影票很有可能就浪费了。如果缩短扫描的时间间隔，第一只能改善不能解决，第二，又会对数据库造成更大的压力。 

那么我们能否有种机制，不用定时扫描，当订单到期了，自然通知我们的应用去处理这些到期的订单呢？ 

####  *来自Java本身的解决方案  

java其实已经为我们提供了问题的方法。我们想，要处理限时支付的问题，肯定是要有个地方保存这些限时订单的信息的，意味着我们需要一个容器，于是我们在Java容器中去寻找。Map? List? Queue? 

看看java为我们提供的容器，我们是个多线程下的应用，会有多个用户同时下订单，所以所有并发不安全的容器首先被排除，并发安全的容器有哪些？一一排除，很巧，java在阻塞队列里为我们提供了一种叫延迟队列delayQueue的容器，刚好可以为我们解决问题。

DelayQueue： 阻塞队列（先进先出）

1）支持阻塞的插入方法：意思是当队列满时，队列会阻塞插入元素的线程，直到队列不满。2）支持阻塞的移除方法：意思是在队列为空时，获取元素的线程会等待队列变为非空。

延迟期满时才能从中提取元素（光队列里有元素还不行）。

Delayed接口使对象成为延迟对象，它使存放在DelayQueue类中的对象具有了激活日期。该接口强制实现下列两个方法。

•	CompareTo(Delayed o)：Delayed接口继承了Comparable接口，因此有了这个方法。让元素按激活日期排队

•	getDelay(TimeUnit unit):这个方法返回到激活日期的剩余时间，时间单位由单位参数指定。

 阻塞队列更多详情，参考VIP课程《并发编程》 

####  *架构师应该多考虑一点！ 

架构师在设计和实现系统时需要考虑些什么？

 功能 ，这个没什么好说，实现一个应用，连基本的功能都没实现，要这个应用有何用？简直就是“一顿操作猛如虎，一看战绩零比五”

 高性能 ，能不能尽快的为用户提供服务和能为多少用户同时提供服务，性能这个东西是个很综合性的东西，从前端到后端，从架构（缓存机制、异步机制）到web容器、数据库本身再到虚拟机到算法、java代码、sql语句的编写，全部都对性能有影响。如何提升性能，要建立在充分的性能测试的基础上，然后一个个的去解决性能瓶颈。对我们今天的应用来讲，我们不想去轮询数据库，其实跟性能有非常大的关系。

 高可用 ，应用正确处理业务，服务用户的时间，这个时间当然是越长越好，希望可以7*24小时。而且哪怕服务器出现了升级，宕机等等情况下，能够以最短的时间恢复，为用户继续服务，但是实际过程中没有哪个网站可以说做到100%，不管是Google，FaceBook，阿里，腾讯，一般来说可以做到99.99%的可用性，已经是相当厉害了，这个水平大概就是一个服务在一年可以做到只有50分钟不可用。这个需要技术、资金、技术人员的水平和责任心，还要运气。

 高伸缩 ，伸缩性是指通过不断向集群中加入服务器的手段来缓解不断上升的用户并发访问压力和不断增长的数据存储需求。就像弹簧一样挂东西一样，用户多，伸一点，用户少，，缩一点。衡量架构是否高伸缩性的主要标准就是是否可用多台服务器构建集群，是否容易向集群中添加新的服务器。加入新的服务器后是否可以提供和原来服务器无差别的服务。集群中可容纳的总的服务器数量是否有限制。

 高扩展 ，的主要标准就是在网站增加新的业务产品时，是否可以实现对现有产品透明无影响，不需要任何改动或者很少改动既有业务功能就可以上线新产品。比如购买电影票的应用，用户购买电影票，现在我们要增加一个功能，用户买了票后，随机抽取用户送限量周边。怎么做到不改动用户下订单功能的基础上增加这个功能。熟悉设计模式的同学，应该很眼熟，这是设计模式中的开闭原则（对扩展开放，对修改关闭）在架构层面的一个原则。

####  *从系统可用性角度考虑：应用重启了怎么办？  

应用重启带来的问题：

保存在Queue中的订单会丢失，这些丢失的订单会在什么时候过期，因为队列里已经没有这个订单了，无法检查了，这些订单就得不到处理了。 

已过期的订单不会被处理，在应用的重启阶段，可能会有一部分订单过期，这部分过期未支付的订单同样也得不到处理，会一直放在数据库里，过期未支付订单所对应的资源比如电影票所对应的座位，就不能被释放出来，让别的用户来购买。

解决之道 ：在系统启动时另行处理

####  *从系统伸缩性角度考虑：应用集群化了怎么办？  

集群化了会带来什么问题？应用之间会相互抢夺订单，特别是在应用重启的时候，重新启动的那个应用会把不属于自己的订单，也全部加载到自己的队列里去，一是造成内存的浪费，二来会造成订单的重复处理，而且加大了数据库的压力。

 解决方案  

让应用分区处理

1、	给每台服务器编号，然后在订单表里登记每条订单的服务器编号；2，更简单的，在订单表里登记每台服务器的IP地址，修改相应的sql语句即可。

几个问题：如果有一台服务器挂了怎么办？运维吃干饭的吗？服务器挂了赶紧启动啊。如果是某台服务器下线或者宕机，起不来怎么搞？这个还是还是稍微有点麻烦，需要人工干预一下，手动把库里的每条订单数据的服务器编号改为目前正常的服务器的编号，不过也就是一条sql语句的事，然后想办法让正常的服务器进行处理（重启正常的服务器）。

####  *能不能同时解决伸缩性和扩展性问题？ 

用delayqueue是队列，分布式情况我们何不直接引入消息中间件呢？一举解决我们应用的伸缩性和扩展性问题

##### ActiveMQ的延迟和定时投递

修改配置文件(activemq.xml)，增加延迟和定时投递支持

< broker xmlns="http://activemq.apache.org/schema/core" brokerName="localhost" dataDirectory="${activemq.data}"   schedulerSupport="true" >

需要把几个描述消息定时调度方式的参数作为属性添加到消息，broker端的调度器就会按照我们想要的行为去处理消息。

一共有4个属性

1：AMQ_SCHEDULED_DELAY ：延迟投递的时间

2：AMQ_SCHEDULED_PERIOD ：重复投递的时间间隔

3：AMQ_SCHEDULED_REPEAT：重复投递次数

4：AMQ_SCHEDULED_CRON：Cron表达式

ActiveMQ也提供了一个封装的消息类型：org.apache.activemq.ScheduledMessage，可以使用这个类来辅助设置，使用例子如：延迟60秒

MessageProducer producer = session.createProducer(destination);

TextMessage message = session.createTextMessage("test msg");

long time = 60 * 1000;

message.setLongProperty(ScheduledMessage.AMQ_SCHEDULED_DELAY, time);

producer.send(message);

 

例子：延迟30秒，投递10次，间隔10秒：

TextMessage message = session.createTextMessage("test msg");

long delay = 30 * 1000;

long period = 10 * 1000;

int repeat = 9;

message.setLongProperty(ScheduledMessage.AMQ_SCHEDULED_DELAY, delay);

message.setLongProperty(ScheduledMessage.AMQ_SCHEDULED_PERIOD, period);

message.setIntProperty(ScheduledMessage.AMQ_SCHEDULED_REPEAT, repeat);

也可使用 CRON 表达式，如message.setStringProperty(ScheduledMessage.AMQ_SCHEDULED_CRON, "0 * * * *");

##### 代码的变化

1、	保存订单SaveOrder.java的时候，作为生产者往消息队列里推入订单，展示和修改MqProducer，这个类当然是要继承IDelayOrder

2、	消息队列会把过期订单发给消费者MqConsume，由它来负责检查订单是否已经支付和过期，来进行下一步处理。

消息队列本身又如何保证可用性和伸缩性？这个就需要ActiveMQ的集群化。

###  构建ActiveMQ集群  

####  *ActiveMQ的集群方式综述 

ActiveMQ的集群方式主要由两种：Master-Slave和Broker Cluster

##### Master-Slave

Master-Slave方式中，只能是Master提供服务，Slave是实时地备份Master的数据，以保证消息的可靠性。当Master失效时，Slave会自动升级为Master，客户端会自动连接到Slave上工作。Master-Slave模式分为四类：Pure Master Slave、Shared File System Master Slave和JDBC Master Slave，以及Replicated LevelDB Store方式 。

Master-Slave方式都不支持负载均衡，但可以解决单点故障的问题，以保证消息服务的可靠性。

##### Broker Cluster

Broker Cluster主要是通过network of Brokers在多个ActiveMQ实例之间进行消息的路由。Broker Cluster模式支持负载均衡，可以提高消息的消费能力，但不能保证消息的可靠性。所以为了支持负载均衡，同时又保证消息的可靠性，我们往往会采用Msater-Slave+Broker Cluster的模式。

#####  注意： 

 以下的测试均在一台机器上进行，为避免多个ActiveMQ之间在启动时发生端口冲突，需要修改每个ActiveMQ的配置文件中MQ的服务端口。如果实际部署在不同的机器，端口的修改是不必要的。 

####  *Pure Master Slave方式 

ActiveMQ5.8以前支持，自从Activemq5.8开始，Activemq的集群实现方式取消了传统的Pure Master Slave方式，并从Activemq5.9增加了基于zookeeper+leveldb的实现方式。

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wps5ta1ef.jpg) 

使用两个ActiveMQ服务器，一个作为Master，Master不需要做特殊的配置；另一个作为Slave，配置activemq.xml文件，在<broker>节点中添加连接到Master的URI和设置Master失效后不关闭Slave。具体配置参考页面：http://activemq.apache.org/pure-master-slave.html

####  *Shared File   *System Master Slave\** **\**方式 

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsdVdAPa.jpg) 

就是利用共享文件系统做ActiveMQ集群，是基于ActiveMQ的默认数据库kahaDB完成的，kahaDB的底层是文件系统。这种方式的集群，Slave的个数没有限制，哪个ActiveMQ实例先获取共享文件的锁，那个实例就是Master，其它的ActiveMQ实例就是Slave，当当前的Master失效，其它的Slave就会去竞争共享文件锁，谁竞争到了谁就是Master。这种模式的好处就是当Master失效时不用手动去配置，只要有足够多的Slave。

如果各个ActiveMQ实例需要运行在不同的机器，就需要用到分布式文件系统了。

####  *Shared   *JDBC Master Slave 

JDBC Master Slave模式和Shared File Sysytem Master Slave模式的原理是一样的，只是把共享文件系统换成了共享数据库。我们只需在所有的ActiveMQ的主配置文件中activemq.xml添加数据源，所有的数据源都指向同一个数据库。

然后修改持久化适配器。这种方式的集群相对Shared File System Master Slave更加简单，更加容易地进行分布式部署，但是如果数据库失效，那么所有的ActiveMQ实例都将失效。

##### 配置修改清单

1、开启网络监控功能（useJmx="true"）

<broker xmlns="http://activemq.apache.org/schema/core" brokerName="localhost" dataDirectory="${activemq.data}" useJmx="true">

2、数据库持久化配置，注释掉之前kahadb消息存储器

<persistenceAdapter>  

  <jdbcPersistenceAdapter dataDirectory="${activemq.data}" dataSource="#mysql-ds" createTablesOnStartup="false" useDatabaseLock="true"/>  

</persistenceAdapter>

3、增加数据源mysql-ds

4、修改客户端上连接url为类似于 failover:(tcp://0.0.0.0:61616,tcp://0.0.0.0:61617,tcp://0.0.0.0:61618)?randomize=false 

注：默认情况下，failover机制从URI列表中随机选择出一个URI进行连接，这可以有效地控制客户端在多个broker上的负载均衡，但是，要使客户端首先连接到主节点，并在主节点不可用时只连接到辅助备份代理，需要设置randomize = false。

5、可以看到只有一台MQ成为Master，其余两台成为slave并会尝试成为Master，并不断重试。且两台slave的管理控制台将无法访问。

##### 测试方法

\1.     先启动生产者，发送几条消息

\2.     启动消费者，可看到接收到的消息

\3.     关闭消费者

\4.     生产者继续发送几条消息-消息A

\5.     停止broker01（可看到生产者端显示连接到broker02（tcp://0.0.0.0:61617）了，同时运行broker02的Shell也显示其成为了Master）

\6.     生产者继续发送几条消息-消息B

\7.     启动消费者

\8.     消费者接收了消息A和消息B，可见broker02接替了broker01的工作，而且储存了之前生产者经过broker01发送的消息

\9.     关闭消费者

\10.   生产者继续发送几条消息-消息C

\11.   停止broker02（可看到生产者端显示连接到broker03（tcp://0.0.0.0:61618）了，同时运行broker03的Shell也显示其成为了Master）

\12.   生产者继续发送几条消息-消息D

\13.   启动消费者

\14.   消费者接收了消息C和消息D，可见broker03接替了broker02的工作，而且储存了之前生产者经过broker02发送的消息

\15.   再次启动broker01，生产者或消费者均未显示连接到broker01(tcp://0.0.0.0:61616)，表明broker01此时只是个Slave

####  *Replicated LevelDB Store 

ActiveMQ5.9以后才新增的特性，使用ZooKeeper协调选择一个node作为master。被选择的master broker node开启并接受客户端连接。 其他node转入slave模式，连接master并同步他们的存储状态。slave不接受客户端连接。所有的存储操作都将被复制到连接至Master的slaves。 

如果master死了，得到了最新更新的slave被允许成为master。推荐运行至少3个replica nodes。 

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wps3sucq6.jpg) 

##### 配置修改清单

1、 使用性能比较好的LevelDB替换掉默认的KahaDB

​		<persistenceAdapter> 

​		 <replicatedLevelDB 

​			directory="${activemq.data}/leveldb" 

​			replicas="3" 

​			bind="tcp://0.0.0.0:62623" 

​			zkAddress="127.0.0.1:2181" 

​			hostname="localhost" 

​			zkPath="/activemq/leveldb-stores"/> 

​		</persistenceAdapter>

配置项说明：

· directory：持久化数据存放地址

· replicas：集群中节点的个数

· bind：集群通信端口

· zkAddress：ZooKeeper集群地址

· hostname：当前服务器的IP地址，如果集群启动的时候报未知主机名错误，那么就需要配置主机名到IP地址的映射关系。

· zkPath：ZooKeeper数据挂载点

2、修改客户端上连接url为 failover:(tcp://0.0.0.0:61616,tcp://0.0.0.0:61617,tcp://0.0.0.0:61618)?randomize=false 

3、可以看到只有一台MQ成为Master，其余两台成为slave。且两台slave的管理控制台将无法访问。

###### **LevelDB****解释**

Leveldb是一个google实现的非常高效的kv数据库，目前的版本1.2能够支持billion级别的数据量了。 在这个数量级别下还有着非常高的性能，采用单进程的服务，性能非常之高，在一台4核Q6600的CPU机器上，每秒钟写数据超过40w，而随机读的性能每秒钟超过10w。由此可以看出，具有很高的随机写，顺序读/写性能，但是随机读的性能很一般，也就是说，LevelDB很适合应用在查询较少，而写很多的场景。LevelDB应用了[LSM](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.44.2782&rep=rep1&type=pdf) (Log Structured Merge) 策略，通过一种类似于归并排序的方式高效地将更新迁移到磁盘，降低索引插入开销。

 限制： 1、非关系型数据模型（NoSQL），不支持sql语句，也不支持索引；2、一次只允许一个进程访问一个特定的数据库；3、没有内置的C/S架构，但开发者可以使用LevelDB库自己封装一个server；

##### 测试方法

同Shared JDBC Master Slave [测试方法](#_测试方法)

 





#  AMQP概论  

##  AMQP  

是应用层协议的一个开放标准,为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同的开发语言等条件的限制。目标是实现一种在全行业广泛使用的标准消息中间件技术，以便降低企业和系统集成的开销，并且向大众提供工业级的集成服务。主要实现有 RabbitMQ。

##  包括的要素 

###  生产者、消费者、消息 

 生产者 :消息的创建者，发送到rabbitmq；

 消费者 ：连接到rabbitmq，订阅到队列上，消费消息，持续订阅(basicConsumer)和单条订阅(basicGet).

 消息： 包含有效载荷和标签，有效载荷指要传输的数据，，标签描述了有效载荷，并且rabbitmq用它来决定谁获得消息，消费者只能拿到有效载荷，并不知道生产者是谁。

###  信道 

 信道 ，概念：信道是生产消费者与rabbit通信的渠道，生产者publish或是消费者subscribe一个队列都是通过信道来通信的。信道是建立在TCP连接上的虚拟连接，什么意思呢？就是说rabbitmq在一条TCP上建立成百上千个信道来达到多个线程处理，这个TCP被多个线程共享，每个线程对应一个信道，信道在rabbit都有唯一的ID ,保证了信道私有性，对应上唯一的线程使用。

疑问：为什么不建立多个TCP连接呢？原因是rabbit保证性能，系统为每个线程开辟一个TCP是非常消耗性能，每秒成百上千的建立销毁TCP会严重消耗系统。所以rabbitmq选择建立多个信道（建立在tcp的虚拟连接）连接到rabbit上。

###  交换器、队列、绑定、路由键 

队列通过路由键（routing  key，某种确定的规则）绑定到交换器，生产者将消息发布到交换器，交换器根据绑定的路由键将消息路由到特定队列，然后由订阅这个队列的消费者进行接收。

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpshCpve7.jpg) 

####  *常见问题 

 如果消息达到无人订阅的队列会怎么办 ？消息会一直在队列中等待，RabbitMq默认队列是无限长度的。

 多个消费者订阅到  同一队列怎么办 ？消息以循环的方式发送给消费者，每个消息只会发送给一个消费者。

 消息路由到了不存在的队列怎么办？ 一般情况下，凉拌，RabbitMq会忽略，当这个消息不存在，也就是这消息丢了。

##  消息的确认 

消费者收到的每一条消息都必须进行确认（自动确认和自行确认）。

消费者在声明队列时，可以指定autoAck参数，当autoAck=false时，RabbitMQ会等待消费者显式发回ack信号后才从内存(和磁盘，如果是持久化消息的话)中移去消息。否则，RabbitMQ会在队列中消息被消费后立即删除它。

采用消息确认机制后，只要令autoAck=false，消费者就有足够的时间处理消息(任务)，不用担心处理消息过程中消费者进程挂掉后消息丢失的问题，因为RabbitMQ会一直持有消息直到消费者显式调用basicAck为止。

当autoAck=false时，对于RabbitMQ服务器端而言，队列中的消息分成了两部分：一部分是等待投递给消费者的消息；一部分是已经投递给消费者，但是还没有收到消费者ack信号的消息。如果服务器端一直没有收到消费者的ack信号，并且消费此消息的消费者已经断开连接，则服务器端会安排该消息重新进入队列，等待投递给下一个消费者（也可能还是原来的那个消费者）。

RabbitMQ不会为未ack的消息设置超时时间，它判断此消息是否需要重新投递给消费者的唯一依据是消费该消息的消费者连接是否已经断开。这么设计的原因是RabbitMQ允许消费者消费一条消息的时间可以很久很久。

##  交换器类型 

共有四种direct,fanout,topic,headers，其种headers(几乎和direct一样)不实用，可以忽略。

###  D  irect 

路由键完全匹配，消息被投递到对应的队列，每个amqp的实现都必须有一个direct交换器，包含一个空白字符串名称的默认交换器。声明一个队列时，会自动绑定到默认交换器，并且以队列名称作为路由键：channel->basic_public($msg,’ ’,’queue-name’)

###  F  anout 

消息广播到绑定的队列

###  T  opic 

通过使用“*”和“#”，使来自不同源头的消息到达同一个队列，”.”将路由键分为了几个标识符，“*”匹配1个，“#”匹配一个或多个。例如日志处理：

假设有交换器log-exchange，

日志级别有error,info,warning，

应用模块有user,order,email，

服务器有 A、B、C、D

路由键的规则为 服务器+“.”+日志级别+“.”+应用模块名，如：A. info .email。

1、要关注A服务器发送的所有应用错误的消息，怎么做？

声明队列名称为“a-app-error-queue”并绑定到交换器上：channel. queueBind (‘a-app-error-queue’,’logs-change’,’A.error.*’)

2、关注B服务器发送的的所有日志，怎么办？

声明队列名称为“b-all-queue”并绑定到交换器上：channel. queueBind (b-all-queue’,’logs-change’,’ B.#’)或channel. queueBind (b-all-queue’,’logs-change’,’ B.*.*’)

3、关注所有服务器发送的email的所有日志，怎么办？

声明队列名称为“email-all-queue”并绑定到交换器上：channel. queueBind (email -all-queue’,’logs-change’,’ *.*.emal’)

4、想要接收所有日志：channel->queue_bind(‘all-log’,’logs-change’,’#’)

 

##  虚拟主机 

虚拟消息服务器，vhost，本质上就是一个mini版的mq服务器，有自己的队列、交换器和绑定，最重要的，自己的权限机制。Vhost提供了逻辑上的分离，可以将众多客户端进行区分，又可以避免队列和交换器的命名冲突。Vhost必须在连接时指定，rabbitmq包含缺省vhost：“/”，通过缺省用户和口令guest进行访问。

rabbitmq里创建用户，必须要被指派给至少一个vhost，并且只能访问被指派内的队列、交换器和绑定。Vhost必须通过rabbitmq的管理控制工具创建。

#  RabbitMQ在Windows下安装和运行 

1、下载Erlang：

http://www.erlang.org/downloads/19.2

2、下载Windows版RabbitMq：

http://www.rabbitmq.com/releases/rabbitmq-server/v3.6.6/rabbitmq-server-3.6.6.exe

3、安装并配置环境变量：

增加变量ERLANG_HOME   C:\Program Files\erl8.2

path下添加  %ERLANG_HOME%\bin，如

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsbtZS27.jpg) 

增加变量RABBITMQ_BASE  C:\Program Files\RabbitMQ Server\rabbitmq_server-3.6.6    

path下添加  %RABBITMQ_BASE%\sbin;%RABBITMQ_BASE%\ebin

4、在开始菜单中启动服务

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wps1QThR8.jpg) 

5、可以在安装目录的sbin下运行rabbitmqctl.bat status检测是否安装成功

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsZbjIF9.jpg) 

#  原生Java客户端进行消息通信 

###  D  irect 

参见代码no-spring模块包cn.enjoyedu.exchange.direct中：

DirectProducer： *direct\** **\**类型交换器的生产者 

NormalConsumer： *普通的消费者 

MulitBindConsumer： *队列绑定到交换器上时，是允许绑定多个路由键的，也就是多重绑定 

MulitChannelConsumer： *一个连接下允许有多个信道 

MulitConsumerOneQueue： *一个队列多个消费者，则会表现出消息在消费者之间的轮询发送。 

###  F  anout 

消息广播到绑定的队列

参见代码no-spring模块包cn.enjoyedu.exchange.fanout中：

通过测试表明，不管我们如何调整生产者和消费者的路由键，都对消息的接受没有影响。

###  T  opic 

参见代码no-spring模块包cn.enjoyedu.exchange.topic中：

通过使用“*”和“#”，使来自不同源头的消息到达同一个队列，”.”将路由键分为了几个标识符，“*”匹配1个，“#”匹配一个或多个。例如日志处理：

假设有交换器log-exchange，

日志级别有error,info,warning，

应用模块有user,order,email，

服务器有 A、B、C、D

路由键的规则为 服务器+“.”+日志级别+“.”+应用模块名，如：A. info .email。

1、要关注A服务器发送的所有应用错误的消息，怎么做？

声明队列名称为“a-app-error-queue”并绑定到交换器上：channel. queueBind (‘a-app-error-queue’,’logs-change’,’A.error.*’)

2、关注B服务器发送的的所有日志，怎么办？

声明队列名称为“b-all-queue”并绑定到交换器上：channel. queueBind (b-all-queue’,’logs-change’,’ B.#’)或channel. queueBind (b-all-queue’,’logs-change’,’ B.*.*’)

3、关注所有服务器发送的email的所有日志，怎么办？

声明队列名称为“email-all-queue”并绑定到交换器上：channel. queueBind (email -all-queue’,’logs-change’,’ *.*.emal’)

4、想要接收所有日志：channel->queue_bind(‘all-log’,’logs-change’,’#’)

#  消息发布时的权衡  

##  失败确认 

在发送消息时设置mandatory标志，告诉RabbitMQ，如果消息不可路由，应该将消息返回给发送者，并通知失败。可以这样认为，开启mandatory是开启故障检测模式。

注意：它只会让RabbitMQ向你通知失败，而不会通知成功。如果消息正确路由到队列，则发布者不会受到任何通知。带来的问题是无法确保发布消息一定是成功的，因为通知失败的消息可能会丢失。

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wps1yHcua.jpg) 

**channel**.addConfirmListener则用来监听RabbitMQ发回的信息。

如何使用，参见代码no-spring模块包cn.enjoyedu.mandatory中。

##  监听器的小甜点 

在信道关闭和连接关闭时，还有两个监听器可以使用

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsL5sIib.jpg) 

##  事务 

事务的实现主要是对信道（Channel）的设置，主要的方法有三个：

\1. channel.txSelect()声明启动事务模式；

\2. channel.txComment()提交事务；

\3. channel.txRollback()回滚事务；

在发送消息之前，需要声明channel为事务模式，提交或者回滚事务即可。

开启事务后，客户端和RabbitMQ之间的通讯交互流程：

· 客户端发送给服务器Tx.Select(开启事务模式)

· 服务器端返回Tx.Select-Ok（开启事务模式ok）

· 推送消息

· 客户端发送给事务提交Tx.Commit

· 服务器端返回Tx.Commit-Ok

以上就完成了事务的交互流程，如果其中任意一个环节出现问题，就会抛出IoException移除，这样用户就可以拦截异常进行事务回滚，或决定要不要重复消息。

那么，既然已经有事务了，为何还要使用发送方确认模式呢，原因是因为事务的性能是非常差的。根据相关资料，事务会降低2~10倍的性能。

##  发送方确认模式  

基于事务的性能问题，RabbitMQ团队为我们拿出了更好的方案，即采用 发送方确认模式， 该模式比事务更轻量，性能影响几乎可以忽略不计。 

原理：生产者将信道设置成confirm模式，一旦信道进入confirm模式，所有在该信道上面发布的消息都将会被指派一个唯一的ID(从1开始)，由这个id在生产者和RabbitMQ之间进行消息的确认。

不可路由的消息，当交换器发现，消息不能路由到任何队列，会进行确认操作，表示收到了消息。如果发送方设置了mandatory模式,则会先调用addReturnListener监听器。

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wps1cyg7b.jpg) 

可路由的消息，要等到消息被投递到所有匹配的队列之后，broker会发送一个确认给生产者(包含消息的唯一ID)，这就使得生产者知道消息已经正确到达目的队列了，如果消息和队列是可持久化的，那么确认消息会在将消息写入磁盘之后发出，broker回传给生产者的确认消息中delivery-tag域包含了确认消息的序列号。

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsle3PVc.jpg) 

confirm模式最大的好处在于他可以是异步的，一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通过回调方法来处理该确认消息，如果RabbitMQ因为自身内部错误导致消息丢失，就会发送一条nack消息，生产者应用程序同样可以在回调方法中处理该nack消息决定下一步的处理。

 Confirm的三种实现方式： 

方式一：channel.waitForConfirms()普通发送方确认模式；消息到达交换器，就会返回true。

方式二：channel.waitForConfirmsOrDie()批量确认模式；使用同步方式等所有的消息发送之后才会执行后面代码，只要有一个消息未到达交换器就会抛出IOException异常。

方式三：channel.addConfirmListener()异步监听发送方确认模式；

如何使用，参见代码no-spring模块包cn.enjoyedu. producerconfirm中。

##  备用交换器 

在第一次声明交换器时被指定，用来提供一种预先存在的交换器，如果主交换器无法路由消息，那么消息将被路由到这个新的备用交换器。

如果发布消息时同时设置了mandatory会发生什么？如果主交换器无法路由消息，RabbitMQ并不会通知发布者，因为，向备用交换器发送消息，表示消息已经被路由了。注意，新的备用交换器就是普通的交换器，没有任何特殊的地方。

使用备用交换器，向往常一样，声明Queue和备用交换器，把Queue绑定到备用交换器上。然后在声明主交换器时，通过交换器的参数，alternate-exchange,，将备用交换器设置给主交换器。

建议备用交换器设置为faout类型，Queue绑定时的路由键设置为“#”

如何使用，参见代码no-spring模块包cn.enjoyedu. backupexchange中。

#  消息的消费  

##  消息的获得方式 

###  拉取Get 

属于一种轮询模型，发送一次get请求，获得一个消息。如果此时RabbitMQ中没有消息，会获得一个表示空的回复。总的来说，这种方式性能比较差，很明显，每获得一条消息，都要和RabbitMQ进行网络通信发出请求。而且对RabbitMQ来说，RabbitMQ无法进行任何优化，因为它永远不知道应用程序何时会发出请求。具体使用，参见代码no-spring模块包cn.enjoyedu.GetMessage中。对我们实现者来说，要在一个循环里，不断去服务器get消息。

###  推送Consume 

属于一种推送模型。注册一个消费者后，RabbitMQ会在消息可用时，自动将消息进行推送给消费者。这种模式我们已经使用过很多次了，具体使用，参见代码no-spring模块包cn.enjoyedu.exchange.direct中。

##  消息的应答 

前面说过，消费者收到的每一条消息都必须进行确认。消息确认后，RabbitMQ才会从队列删除这条消息，RabbitMQ不会为未确认的消息设置超时时间，它判断此消息是否需要重新投递给消费者的唯一依据是消费该消息的消费者连接是否已经断开。这么设计的原因是RabbitMQ允许消费者消费一条消息的时间可以很久很久。

###  自动确认 

消费者在声明队列时，可以指定autoAck参数，当autoAck=true时，一旦消费者接收到了消息，就视为自动确认了消息。如果消费者在处理消息的过程中，出了错，就没有什么办法重新处理这条消息，所以我们很多时候，需要在消息处理成功后，再确认消息，这就需要手动确认。

###  自行手动确认 

当autoAck=false时，RabbitMQ会等待消费者显式发回ack信号后才从内存(和磁盘，如果是持久化消息的话)中移去消息。否则，RabbitMQ会在队列中消息被消费后立即删除它。

采用消息确认机制后，只要令autoAck=false，消费者就有足够的时间处理消息(任务)，不用担心处理消息过程中消费者进程挂掉后消息丢失的问题，因为RabbitMQ会一直持有消息直到消费者显式调用basicAck为止。

当autoAck=false时，对于RabbitMQ服务器端而言，队列中的消息分成了两部分：一部分是等待投递给消费者的消息；一部分是已经投递给消费者，但是还没有收到消费者ack信号的消息。如果服务器端一直没有收到消费者的ack信号，并且消费此消息的消费者已经断开连接，则服务器端会安排该消息重新进入队列，等待投递给下一个消费者（也可能还是原来的那个消费者）。

如何使用，参见代码no-spring模块包cn.enjoyedu. ackfalse中。

通过运行程序，启动两个消费者A、B，都可以收到消息，但是其中有一个消费者A不会对消息进行确认，当把这个消费者A关闭后，消费者B又会收到本来发送给消费者A的消息。所以我们一般使用手动确认的方法是，将消息的处理放在try/catch语句块中，成功处理了，就给RabbitMQ一个确认应答，如果处理异常了，就在catch中，进行消息的拒绝，如何拒绝，参考《消息的拒绝》章节。

 

##  QoS预取模式 

在确认消息被接收之前，消费者可以预先要求接收一定数量的消息，在处理完一定数量的消息后，批量进行确认。如果消费者应用程序在确认消息之前崩溃，则所有未确认的消息将被重新发送给其他消费者。所以这里存在着一定程度上的可靠性风险。

这种机制一方面可以实现限速（将消息暂存到RabbitMQ内存中）的作用，一方面可以保证消息确认质量（比如确认了但是处理有异常的情况）。

注意：消费确认模式必须是非自动ACK机制（这个是使用baseQos的前提条件，否则会Qos不生效），然后设置basicQos的值；另外，还可以基于consume和channel的粒度进行设置（global）。

具体使用，参见代码no-spring模块包cn.enjoyedu. qos中。我们可以进行批量确认，也可以进行单条确认。

basicQos方法参数详细解释：

prefetchSize：最多传输的内容的大小的限制，0为不限制，但据说prefetchSize参数，rabbitmq没有实现。

prefetchCount：会告诉RabbitMQ不要同时给一个消费者推送多于N个消息，即一旦有N个消息还没有ack，则该consumer将block掉，直到有消息ack

global：true\false 是否将上面设置应用于channel，简单点说，就是上面限制是channel级别的还是consumer级别。

如果同时设置channel和消费者，会怎么样？AMQP规范没有解释如果使用不同的全局值多次调用basic.qos会发生什么。 RabbitMQ将此解释为意味着两个预取限制应该彼此独立地强制执行; 消费者只有在未达到未确认消息限制时才会收到新消息。

channel.basicQos(10, false); **// Per consumer limit**

channel.basicQos(15, true);  **// Per channel limit**

channel.basicConsume("my-queue1", false, consumer1);

channel.basicConsume("my-queue2", false, consumer2);

也就是说，整个通道加起来最多允许15条未确认的消息，每个消费者则最多有10条消息。

##  消费者中的事务 

使用方法和生产者一致

假设消费者模式中使用了事务，并且在消息确认之后进行了事务回滚，会是什么样的结果？

结果分为两种情况：

\1. autoAck=false手动应对的时候是支持事务的，也就是说即使你已经手动确认了消息已经收到了，但RabbitMQ对消息的确认会等事务的返回结果，再做最终决定是确认消息还是重新放回队列，如果你手动确认之后，又回滚了事务，那么以事务回滚为准，此条消息会重新放回队列；

\2. autoAck=true如果自动确认为true的情况是不支持事务的，也就是说你即使在收到消息之后在回滚事务也是于事无补的，队列已经把消息移除了。

 

##  可靠性和性能的权衡 

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpstDJtKd.jpg) 

#  消息的拒绝  

##  Reject  和  Nack 

消息确认可以让RabbitMQ知道消费者已经接受并处理完消息。但是如果消息本身或者消息的处理过程出现问题怎么办？需要一种机制，通知RabbitMQ，这个消息，我无法处理，请让别的消费者处理。这里就有两种机制，Reject和Nack。

Reject在拒绝消息时，可以使用requeue标识，告诉RabbitMQ是否需要重新发送给别的消费者。不重新发送，一般这个消息就会被RabbitMQ丢弃。Reject一次只能拒绝一条消息。

Nack则可以一次性拒绝多个消息。这是RabbitMQ对AMQP规范的一个扩展。

具体使用，参见代码no-spring模块包cn.enjoyedu. rejectmsg中。通过RejectRequeuConsumer可以看到当requeue参数设置为true时，消息发生了重新投递。

##  死信交换器DLX 

RabbitMQ对AMQP规范的一个扩展。被投递消息被拒绝后的一个可选行为，往往用在对问题消息的诊断上。

消息变成死信一般是以下几种情况：

· 消息被拒绝，并且设置 requeue 参数为 false

· 消息过期

· 队列达到最大长度

死信交换器仍然只是一个普通的交换器，创建时并没有特别要求和操作。在创建队列的时候，声明该交换器将用作保存被拒绝的消息即可，相关的参数是x-dead-letter-exchange。

具体使用，参见代码no-spring模块包cn.enjoyedu.dlx中。

通过运行程序可以看到，生产者产生了3条消息，分别是error,info,warn，两个消费者WillMakeDlxConsumer和WillMakeWarnDlxConsumer都拒绝了两条消息，而投送到死信队列后，可以发现根据投送死信时的路由键，不同的消费者有些可以接受到消息，有些则不行。

###  和备用交换器的区别 

1、备用交换器是主交换器无法路由消息，那么消息将被路由到这个新的备用交换器，而死信交换器则是接收过期或者被拒绝的消息。

2、备用交换器是在声明主交换器时发生联系，而死信交换器则声明队列时发生联系。

#  控制队列  

参见代码no-spring模块包cn.enjoyedu. setQueue中

##  临时队列 

###  自动删除队列 

自动删除队列和普通队列在使用上没有什么区别，唯一的区别是，当消费者断开连接时，队列将会被删除。自动删除队列允许的消费者没有限制，也就是说当这个队列上最后一个消费者断开连接才会执行删除。

自动删除队列只需要在声明队列时，设置属性auto-delete标识为true即可。系统声明的随机队列，缺省就是自动删除的。

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpslIV9ye.jpg) 

###  单消费者队列 

普通队列允许的消费者没有限制，多个消费者绑定到多个队列时，RabbitMQ会采用轮询进行投递。如果需要消费者独占队列，在队列创建的时候，设定属性exclusive为true。

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpshm3Qnf.jpg) 

###  自动过期队列 

指队列在超过一定时间没使用，会被从RabbitMQ中被删除。什么是没使用？

一定时间内没有Get操作发生

没有Consumer连接在队列上

特别的：就算一直有消息进入队列，也不算队列在被使用。

通过声明队列时，设定x-expires参数即可，单位毫秒。

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsTkozcg.jpg) 

##  永久队列 

###  队列的持久性 

持久化队列和非持久化队列的区别是，持久化队列会被保存在磁盘中，固定并持久的存储，当Rabbit服务重启后，该队列会保持原来的状态在RabbitMQ中被管理，而非持久化队列不会被保存在磁盘中，Rabbit服务重启后队列就会消失。

非持久化比持久化的优势就是，由于非持久化不需要保存在磁盘中，所以使用速度就比持久化队列快。即是非持久化的性能要高于持久化。而持久化的优点就是会一直存在，不会随服务的重启或服务器的宕机而消失。

在声明队列时，将属性durable设置为“false”，则该队列为非持久化队列，设置成“true”时，该队列就为持久化队列

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wps90jj1g.jpg) 

##  队列级别消息过期 

就是为每个队列设置消息的超时时间。只要给队列设置x-message-ttl 参数，就设定了该队列所有消息的存活时间，时间单位是毫秒。如果声明队列时指定了死信交换器，则过期消息会成为死信消息。

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsxxf4Ph.jpg) 

##  队列保留参数列表  

| 参数名                    | 目的                               |
| ------------------------- | ---------------------------------- |
| x-dead-letter-exchange    | 死信交换器                         |
| x-dead-letter-routing-key | 死信消息的可选路由键               |
| x-expires                 | 队列在指定毫秒数后被删除           |
| x-ha-policy               | 创建HA队列                         |
| x-ha-nodes                | HA队列的分布节点                   |
| x-max-length              | 队列的最大消息数                   |
| x-message-ttl             | 毫秒为单位的消息过期时间，队列级别 |
| x-max-priority            | 最大优先值为255的队列优先排序功能  |

#  消息的属性  

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsv3JSEi.jpg) 

在发送消息时，我们还可以对消息的属性做更细微的控制，比如构建Request-Response模式，参见代码no-spring模块包cn.enjoyedu. setmsg。

##  消息存活时间 

当队列消息的TTL 和消息TTL都被设置，时间短的TTL设置生效。如果将一个过期消息发送给RabbitMQ，该消息不会路由到任何队列，而是直接丢弃。

为消息设置TTL有一个问题：RabbitMQ只对处于队头的消息判断是否过期（即不会扫描队列），所以，很可能队列中已存在死消息，但是队列并不知情。这会影响队列统计数据的正确性，妨碍队列及时释放资源。

##  消息的持久化 

默认情况下，队列和交换器在服务器重启后都会消失，消息当然也是。将队列和交换器的durable属性设为true，缺省为false，但是消息要持久化还不够，还需要将消息在发布前，将投递模式设置为2。消息要持久化，必须要有持久化的队列、交换器和投递模式都为2。

消息属性的设置方法，包括如何将消息的持久化，参见代码no-spring模块包cn.enjoyedu.MsgDurable中

#  集成和实战  

##  与Spring集成 

具体代码实现，参见rq-spring-with和rq-spring-with-consumer模块

###  pom文件 

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsTSjJtj.jpg) 

###  统一配置 

####  *配置文件中增加命名空间 

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsJx2Aik.jpg) 

####  *连接相关配置： 

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsxw9t7k.jpg) 

###  生产者端 

####  *RabbitTemplate 

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsbljoWl.jpg) 

或下面这种声明方式也是可以的。

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpspLbkLm.jpg) 

####  *队列和交换器 

可以在生产者配置文件中增加队列和交换器

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsbn3gAn.jpg) 

####  *代码 

发送消息时，使用 rabbitTemplate 即可。同时还可以给消息配置属性MessageProperties。

###  消费者端 

####  *队列和交换器、 

消费者中也可配置队列和交换器，以及指定队列和交换器绑定的路由键

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsBLCfpo.jpg) 

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsRDAfep.jpg) 

####  *消费者bean 

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsZaLg3p.jpg) 

或![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wps1M5iSq.jpg)

都可以

####  *监听容器 

将消费者bean和队列联系起来

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsRgJmHr.jpg) 

####  *代码 

消费者实现MessageListener接口即可。

##  实战-  应用解耦 

###  场景： 

用户下订单买商品，订单处理成功后，去扣减库存，在这个场景里，订单系统是生产者，库存系统是消费者。

库存是必须扣减的，在业务上来说，有库存直接扣减即可，没库存或者低于某个阈值，可以扣减成功，不过要通知其他系统（如通知采购系统尽快采购，通知用户订单系统我们会尽快调货）。

###  RPC实现 

通过RPC的实现，可以看到RPC会造成耦合。一旦库存系统失败，订单系统也会跟着失败。我们希望库存系统本身的失败，不影响订单系统的继续执行，在业务流程上，进行订单系统和库存系统的解耦。

###  消息中间件的实现 

对于我们消息模式的实现，为保证库存必须有扣减，我们要考虑几个问题：

1、订单系统发给Mq服务器的扣减库存的消息必须要被Mq服务器接收到，意味着需要使用发送者确认。

2、Mq服务器在扣减库存的消息被库存服务正确处理前必须一直保存，那么需要消息进行持久化。

3、某个库存服务器出了问题，扣减库存的消息要能够被其他正常的库存服务处理，需要我们自行对消费进行确认，意味着不能使用消费者自动确认，而应该使用手动确认。

所以生产者订单系统这边需要 ，配置文件中队列和交换器进行持久化，消息发送时的持久化，发送者确认的相关配置和代码。

所以消费者库存系统这边要进行手动确认。

###  总结：与Spring集成时的更多配置 

####  *发送者确认 

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wps7MUsws.jpg) 

设置发送消息时的mandatory以及接收RabbitMQ中间件的应答

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsBuCAlt.jpg) 

####  *交换器持久化配置 

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsnKHJau.jpg) 

####  *消息持久化 

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpstzZTZu.jpg) 

####  *队列参数(包括持久化)配置 

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpshFl5Ov.jpg) 

####  *消费者手动确认消息 

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsfmVhEw.jpg) 

处理库存类要实现ChannelAwareMessageListener。

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpszVIvtx.jpg) 

和对消息确认或拒绝![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsHQtKiy.jpg)

##  SpringBoot整合RabbitMQ 

1、 maven依赖

2、 application.properties文件

3、 基本的配置，如声明RabbitTemplate、队列、各种交换器如fanout，topic等、队列和交换器绑定的使用

4、 发送者确认模式的使用

5、 消费者确认模式的使用，类UserReceiver

访问方法：http://localhost:8080/rabbit/hello等

 

#  RabbitMQ安装  

##  安装过程 

在Linux(以CentOS7为例)下安装RabbitMQ

1、wget https://packages.erlang-solutions.com/erlang-solutions-1.0-1.noarch.rpm

2、rpm -Uvh erlang-solutions-1.0-1.noarch.rpm

3、yum install epel-release

4、yum install erlang

5、wget http://www.rabbitmq.com/releases/rabbitmq-server/v3.6.6/rabbitmq-server-3.6.6-1.el7.noarch.rpm

6、yum install rabbitmq-server-3.6.6-1.el7.noarch.rpm

##  RabbitMQ常用端口 

 client端通信端口： 5672     

 管理端口 ： 15672   

 server间内部通信端口： 25672 

##  可能的问题 

如端口出现不能访问，考虑是否防火墙问题，可以使用形如以下命令开启或直接关闭防火墙：

firewall-cmd --add-port=15672/tcp --permanent

运行rabbitmqctl status出现Error: unable to connect to node rabbit@controller: nodedown之类问题考虑如下几种解决办法： 

1、重启服务 

service rabbitmq-server stop

service rabbitmq-server start

2、检查/var/lib/rabbitmq中是否存在.erlang.cookie，没有则新建一个，里面随便输入一段字符串 

3、重新安装服务 

4、百度或者Google一下 

#  管理RabbitMQ  

##  管理 

###  日志一般存放位置  

[/var/log/rabbitmq/rabbit@centosvm.log](mailto:/var/log/rabbitmq/rabbit@centosvm.log) 

[/var/log/rabbitmq/rabbit@centosvm-sasl.log](mailto:/var/log/rabbitmq/rabbit@centosvm-sasl.log) 

###  管理虚拟主机  

rabbitmqctl add_vhost [vhost_name] 

rabbitmqctl list_vhosts 

###  启动和关闭rabbitmq 

####  *以服务方式 

service rabbitmq-server stop

service rabbitmq-server start

service rabbitmq-server status

####  *以应用程序方式 

rabbitmq-server会启动Erlang节点和Rabbitmq应用 

rabbitmqctl stop会关闭Erlang节点和Rabbitmq应用 

rabbitmqctl status 可以检查消息节点是否正常

Rabbitmq配置文件放在 /etc/rabbitmq 下，名为rabbitmq.config，没有且需要使用则可以自己新建一个

####  *单独关闭RabbitMQ应用 

rabbitmqctl stop_app关闭Rabbitmq应用 

rabbitmqctl start_app启动Rabbitmq应用

###  用户管理  

rabbitmqctl add_user [username] [pwd]

rabbitmqctl delete_user [username]

rabbitmqctl  change_password  Username  Newpassword

rabbitmqctl  list_users

###  用户权限控制  

####  *guest用户 

guest是默认用户，具有默认virtual host "/"上的全部权限，仅能通过localhost访问RabbitMQ包括Plugin，建议删除或更改密码。可通过将配置文件中loopback_users来取消其本地访问的限制：[{rabbit, [{loopback_users, []}]}]

####  *用户权限 

用户仅能对其所能访问的virtual hosts中的资源进行操作。这里的资源指的是virtual hosts中的exchanges、queues等，操作包括对资源进行配置、写、读。配置权限可创建、删除、资源并修改资源的行为，写权限可向资源发送消息，读权限从资源获取消息。比如：

exchange和queue的declare与delete分别需要：exchange和queue上的配置权限

queue的bind与unbind需要：queue写权限，exchange的读权限

发消息(publish)需exchange的写权限

获取或清除(get、consume、purge)消息需queue的读权限

对何种资源具有配置、写、读的权限通过正则表达式来匹配，具体命令如下：

rabbitmqctl set_permissions [-p <vhostpath>] <user> <conf> <write> <read>

如用户Mark在虚拟主机logHost上的所有权限： 

rabbitmqctl set_permissions –p logHost Mark  '.*' '.*'  '.*' 

###  设置用户角色： 

rabbitmqctl  set_user_tags  User  Tag

User为用户名， Tag为角色名(对应于下面的administrator，monitoring，policymaker，management)

####  *RabbitMQ的用户角色分类 

none、management、policymaker、monitoring、administrator

##### none

不能访问 management plugin，通常就是普通的生产者和消费者

##### management

普通的生产者和消费者加：

列出自己可以通过AMQP登入的virtual hosts  

查看自己的virtual hosts中的queues, exchanges 和 bindings

查看和关闭自己的channels 和 connections

查看有关自己的virtual hosts的“全局”的统计信息，包含其他用户在这些virtual hosts中的活动。

##### policymaker 

management可以做的任何事加：

查看、创建和删除自己的virtual hosts所属的policies和parameters

##### monitoring  

management可以做的任何事加：

列出所有virtual hosts，包括他们不能登录的virtual hosts

查看其他用户的connections和channels

查看节点级别的数据如clustering和memory使用情况

查看真正的关于所有virtual hosts的全局的统计信息

##### administrator  

policymaker和monitoring可以做的任何事加:

创建和删除virtual hosts

查看、创建和删除users

查看创建和删除permissions

关闭其他用户的connections

##  查看 

###  查看队列  

rabbitmqctl list_queues

###  查看交换器  

rabbitmqctl list_exchanges

###  查看绑定  

rabbitmqctl list_bindings 

#  RabbitMQ集群  

##  RabbitMQ內建集群 

###  內建集群的设计目标 

1、允许消费者和生产者在节点崩溃的情况下继续运行；2、通过添加节点线性扩展消息通信的吞吐量。

####  *可以保证消息的万无一失吗？ 

不行，当一个节点崩溃时，该节点上队列的消息也会消失，rabbitmq默认不会将队列的消息复制到整个集群上。

###  集群中的队列和交换器 

####  *队列 

集群中队列信息只在队列的所有者节点保存队列的所有信息，其他节点只知道队列的元数据和指向所有者节点的指针，节点崩溃时，该节点的队列和其上的绑定信息都消失了。

为什么集群不复制队列内容和状态到所有节点：1）存储空间；2）性能，如果消息需要复制到集群中每个节点，网络开销不可避免，持久化消息还需要写磁盘。

所以其他节点接收到不属于该节点的队列的消息时会将该消息传递给该队列的所有者节点上。

####  *交换器 

本质上是个这个交换器的名称和队列的绑定列表，可以看成一个类似于hashmap的映射表，所以交换器会在整个集群上复制。

####  *元数据 

队列元数据：队列名称和属性（是否可持久化，是否自动删除）

交换器元数据：交换器名称、类型和属性

绑定元数据：交换器和队列的绑定列表

vhost元数据：vhost内的相关属性，如安全属性等等

###  集群中的节点 

要么是内存节点，要么是磁盘节点。怎么区分？就是节点将队列、交换器、用户等等信息保存在哪里？单节点肯定是磁盘类型。集群中可以有内存节点，为了性能的考虑，全部是磁盘节点，当声明队列、交换器等等时，rabbitmq必须将数据保存在所有节点后才能表示操作完成。

Rabbitmq只要求集群中至少有一个磁盘节点，从高可用的角度讲每个集群应该至少配备两个磁盘节点。因为只有一个磁盘节点的情况下，当这个磁盘节点崩溃时，集群可以保持运行，但任何修改操作，比如创建队列、交换器、添加和删除集群节点都无法进行。

##  构建我们自己的集群 

###  集群常用命令 

rabbitmqctl join_cluster [rabbit@node1]将节点加入集群

rabbitmqctl cluster_status 查询集群状态

rabbitmqctl reset 严格来说，不属于集群命令，reset的作用是将node节点恢复为空白状态，包括但不限于，比如，用户信息，虚拟主机信息，所有持久化的消息。在集群下，通过这个命令，可以让节点离开集群。

###  集群下的注意事项 

元数据的变更，我们知道，这些消息都要记录在磁盘节点上。当有节点离开集群时，所有的磁盘节点上都要记录这个信息。如果磁盘节点在离开集群时不用reset命令，会导致集群认为该节点发生了故障，并会一直等待该节点恢复才允许新节点加入，所以，当磁盘节点是被暴力从集群中脱离时，有可能导致集群永久性的无法变更。

###  本机集群(建议不要随意尝试)： 

RABBITMQ_NODE_PORT=5672 RABBITMQ_NODENAME=rabbit rabbitmq-server -detached 

RABBITMQ_NODE_PORT=5673 RABBITMQ_NODENAME=rabbit_1 rabbitmq-server -detached 

RABBITMQ_NODE_PORT=5674 RABBITMQ_NODENAME=rabbit_2 rabbitmq-server -detached 

rabbitmqctl -n rabbit_1@centosvm stop_app

rabbitmqctl -n rabbit_1@centosvm reset

rabbitmqctl -n rabbit_1@centosvm join_cluster rabbit@centosvm

rabbitmqctl -n rabbit_1@centosvm start_app

rabbitmqctl cluster_status

rabbitmqctl -n rabbit_2@centosvm stop_app

rabbitmqctl -n rabbit_2@centosvm reset

rabbitmqctl -n rabbit_2@centosvm join_cluster rabbit@centosvm --ram 

rabbitmqctl -n rabbit_2@centosvm start_app

rabbitmqctl cluster_status

从外部要访问虚拟机中的mq记得在防火墙中打开端口

firewall-cmd --add-port=5673/tcp --permanent 

firewall-cmd --add-port=5674/tcp --permanent 

 

rabbitmqctl add_user mq mq

rabbitmqctl set_permissions mq ".*" ".*" ".*"

rabbitmqctl set_user_tags mq administrator

rabbitmq-plugins -n rabbit_1@centosvm enable rabbitmq_management

###  多机下的集群 

Rabbitmq集群对延迟非常敏感，只能在本地局域网内使用。

1、 修改 /etc/hosts

192.168.1.1 node1

192.168.1.2 node2

192.168.1.3 node3

2、Erlang Cookie 文件：/var/lib/rabbitmq/.erlang.cookie。将 node1 的该文件复制到 node2、node3，由于这个文件权限是 400，所以需要先修改 node2、node3 中的该文件权限为 777，然后将 node1 中的该文件拷贝到 node2、node3，最后将权限和所属用户/组修改回来。

3、运行各节点

4、在node2、node3上分别运行

[root@node2 ~]# rabbitmqctl stop_app

[root@node2 ~]./rabbitmqctl reset

[root@node2 ~]# rabbitmqctl join_cluster rabbit@node1

[root@node2 ~]# rabbitmqctl start_app

rabbitmqctl cluster_status

内存节点则是rabbitmqctl join_cluster rabbit@node1 --ram

###  移除集群中的节点 

[root@node2 ~]# rabbitmqctl stop_app

[root@node2 ~]./rabbitmqctl reset

[root@node2 ~]# rabbitmqctl start_app

#  RabbitMQ集群高可用 

##  镜像队列 

###  什么是镜像队列 

如果RabbitMQ集群是由多个broker节点构成的，那么从服务的整体可用性上来讲，该集群对于单点失效是有弹性的，但是同时也需要注意：尽管exchange和binding能够在单点失效问题上幸免于难，但是queue和其上持有的message却不行，这是因为queue及其内容仅仅存储于单个节点之上，所以一个节点的失效表现为其对应的queue不可用。

引入RabbitMQ的镜像队列机制，将queue镜像到cluster中其他的节点之上。在该实现下，如果集群中的一个节点失效了，queue能自动地切换到镜像中的另一个节点以保证服务的可用性。在通常的用法中，针对每一个镜像队列都包含一个master和多个slave，分别对应于不同的节点。slave会准确地按照master执行命令的顺序进行命令执行，故slave与master上维护的状态应该是相同的。除了publish外所有动作都只会向master发送，然后由master将命令执行的结果广播给slave们，故看似从镜像队列中的消费操作实际上是在master上执行的。

RabbitMQ的镜像队列同时支持publisher confirm和事务两种机制。在事务机制中，只有当前事务在全部镜像queue中执行之后，客户端才会收到Tx.CommitOk的消息。同样的，在publisher confirm机制中，向publisher进行当前message确认的前提是该message被全部镜像所接受了。

###  镜像队列的配置 

####  *代码 

Map<String, Object> args = new HashMap<String, Object>();

args.put("x-ha-policy", "all");

在声明队列时传入channel.queueDeclare(queueName,false,false, false, args);

####  *控制台 

镜像队列的配置通过添加policy完成，policy添加的命令为：

rabbitmqctl set_policy [-p Vhost] Name Pattern Definition [Priority]

-p Vhost： 可选参数，针对指定vhost下的queue进行设置

Name: policy的名称

Pattern: queue的匹配模式(正则表达式)

Definition：镜像定义，包括三个部分ha-mode, ha-params, ha-sync-mode

  ha-mode:指明镜像队列的模式，有效值为 all/exactly/nodes

​    all：表示在集群中所有的节点上进行镜像

​    exactly：表示在指定个数的节点上进行镜像，节点的个数由ha-params指定

​    nodes：表示在指定的节点上进行镜像，节点名称通过ha-params指定

  ha-params：ha-mode模式需要用到的参数

  ha-sync-mode：进行队列中消息的同步方式，有效值为automatic和manual

priority：可选参数，policy的优先级

例如，对队列名称以“queue_”开头的所有队列进行镜像，并在集群的两个节点上完成进行，policy的设置命令为：

rabbitmqctl set_policy ha-queue-two "^queue_" '{"ha-mode":"exactly","ha-params":2,"ha-sync-mode":"automatic"}'

windows下将单引号改为双引号(rabbitmqctl set_policy ha-all “^ha.” “{“”ha-mode”“:”“all”“}”)

 补充： 

可通过如下命令确认哪些salve在同步：

rabbitmqctl list_queues name slave_pids synchronised_slave_pids

手动同步queue：

rabbitmqctl sync_queue name

取消queue同步：

rabbitmqctl cancel_sync_queue name

###  使用HAProxy  

处理节点选择，故障服务器检测和负载分布可以使用HAProxy，具体如何安装，参考文档《安装HAProxy》![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsTuvb8y.png)

#  RabbitMQ的Web控制台 

运行rabbitmq-plugins enable rabbitmq_management  

重启RabbitMQ

在浏览中打开http://localhost:15672





#  Kafka入门 

##  什么是Kafka 

kafka最初是LinkedIn的一个内部基础设施系统。最初开发的起因是，LinkedIn虽然有了数据库和其他系统可以用来存储数据，但是缺乏一个可以帮助处理持续数据流的组件。所以在设计理念上，开发者不想只是开发一个能够存储数据的系统，如关系数据库、Nosql数据库、搜索引擎等等，更希望把数据看成一个持续变化和不断增长的流，并基于这样的想法构建出一个数据系统，一个数据架构。

Kafka可以看成一个流平台，这个平台上可以发布和订阅数据流，并把他们保存起来，进行处理。Kafka有点像消息系统，允许发布和订阅消息流，但是它和传统的消息系统有很大的差异，首先，Kafka是个现代分布式系统，以集群的方式运行，可以自由伸缩。其次，Kafka可以按照要求存储数据，保存多久都可以，第三，流式处理将数据处理的层次提示到了新高度，消息系统只会传递数据，Kafka的流式处理能力可以让我们用很少的代码就能动态地处理派生流和数据集。所以Kafka不仅仅是个消息中间件。

同时在大数据领域，Kafka还可以看成实时版的Hadoop，Hadoop可以存储和定期处理大量的数据文件，往往以TB计数，而Kafka可以存储和持续处理大型的数据流。Hadoop主要用在数据分析上，而Kafka因为低延迟，更适合于核心的业务应用上。

本次课程，将会以kafka_2.11-0.10.1.1版本为主，其余版本不予考虑。

##  Kafka中的基本概念 

###  消息和批次 

 消息 ，Kafka里的数据单元，也就是我们一般消息中间件里的消息的概念。消息由字节数组组成。消息还可以包含键，用以对消息选取分区。

为了提高效率，消息被分批写入Kafka。 批次 就是一组消息，这些消息属于同一个主题和分区。如果只传递单个消息，会导致大量的网络开销，把消息分成批次传输可以减少这开销。但是，这个需要权衡，批次里包含的消息越多，单位时间内处理的消息就越多，单个消息的传输时间就越长。如果进行压缩，可以提升数据的传输和存储能力，但需要更多的计算处理。

###  主题和分区 

Kafka里的消息用 主题 进行分类，主题下有可以被分为若干个 分区 。分区本质上是个提交日志，有新消息，这个消息就会以追加的方式写入分区，然后用先入先出的顺序读取。

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsbF2yQT.jpg) 

但是因为主题会有多个分区，所以在整个主题的范围内，是无法保证消息的顺序的，单个分区则可以保证。

Kafka通过分区来实现数据冗余和伸缩性，因为分区可以分布在不同的服务器上，那就是说一个主题可以跨越多个服务器。

前面我们说Kafka可以看成一个流平台，很多时候，我们会把一个主题的数据看成一个流，不管有多少个分区。

###  生产者和消费者、偏移量、消费者群组 

就是一般消息中间件里生产者和消费者的概念。一些其他的高级客户端API，像数据管道API和流式处理的Kafka Stream，都是使用了最基本的生产者和消费者作为内部组件，然后提供了高级功能。

生产者默认情况下把消息均衡分布到主题的所有分区上，如果需要指定分区，则需要使用消息里的消息键和分区器。

消费者订阅主题，一个或者多个，并且按照消息的生成顺序读取。消费者通过检查所谓的偏移量来区分消息是否读取过。偏移量是一种元数据，一个不断递增的整数值，创建消息的时候，Kafka会把他加入消息。在一个分区里，每个消息的偏移量是唯一的。每个分区最后读取的消息偏移量会保存到Zookeeper或者Kafka上，这样分区的消费者关闭或者重启，读取状态都不会丢失。

多个消费者可以构成一个消费者群组。怎么构成？共同读取一个主题的消费者们，就形成了一个群组。群组可以保证每个分区只被一个消费者使用。

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsP3mYye.jpg) 

消费者和分区之间的这种映射关系叫做消费者对分区的所有权关系，很明显，一个分区只有一个消费者，而一个消费者可以有多个分区。

###  Broker和集群 

一个独立的Kafka服务器叫Broker。broker的主要工作是，接收生产者的消息，设置偏移量，提交消息到磁盘保存；为消费者提供服务，响应请求，返回消息。在合适的硬件上，单个broker可以处理上千个分区和每秒百万级的消息量。

多个broker可以组成一个集群。每个集群中broker会选举出一个集群控制器。控制器会进行管理，包括将分区分配给broker和监控broker。

集群里，一个分区从属于一个broker，这个broker被称为首领。但是分区可以被分配给多个broker，这个时候会发生分区复制。

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpstefphz.jpg) 

分区复制带来的好处是，提供了消息冗余。一旦首领broker失效，其他broker可以接管领导权。当然相关的消费者和生产者都要重新连接到新的首领上。

###  保留消息 

在一定期限内保留消息是Kafka的一个重要特性，Kafka  broker默认的保留策略是：要么保留一段时间，要么保留一定大小。到了限制，旧消息过期并删除。但是每个主题可以根据业务需求配置自己的保留策略。

#  为什么选择Kafka  

##  优点 

多生产者和多消费者

基于磁盘的数据存储，换句话说，Kafka的数据天生就是持久化的。

高伸缩性，Kafka一开始就被设计成一个具有灵活伸缩性的系统，对在线集群的伸缩丝毫不影响整体系统的可用性。

高性能，结合横向扩展生产者、消费者和broker，Kafka可以轻松处理巨大的信息流，同时保证亚秒级的消息延迟。

##  常见场景 

###  活动跟踪 

跟踪网站用户和前端应用发生的交互，比如页面访问次数和点击，将这些信息作为消息发布到一个或者多个主题上，这样就可以根据这些数据为机器学习提供数据，更新搜素结果等等。

###  传递消息 

标准消息中间件的功能

###  收集指标和日志 

收集应用程序和系统的度量监控指标，或者收集应用日志信息，通过Kafka路由到专门的日志搜索系统，比如ES。

###  提交日志 

收集其他系统的变动日志，比如数据库。可以把数据库的更新发布到Kafka上，应用通过监控事件流来接收数据库的实时更新，或者通过事件流将数据库的更新复制到远程系统。

还可以当其他系统发生了崩溃，通过重放日志来恢复系统的状态。

###  流处理 

操作实时数据流，进行统计、转换、复杂计算等等。随着大数据技术的不断发展和成熟，无论是传统企业还是互联网公司都已经不再满足于离线批处理，实时流处理的需求和重要性日益增长。

近年来业界一直在探索实时流计算引擎和API，比如这几年火爆的Spark Streaming、Kafka Streaming、Beam和Flink，其中阿里双11会场展示的实时销售金额，就用的是流计算，是基于Flink，然后阿里在其上定制化的Blink。

#  Kafka的安装、管理和配置 

##  安装 

###  预备环境 

Kafka是Java生态圈下的一员，用Scala编写，运行在Java虚拟机上，所以安装运行和普通的Java程序并没有什么区别。

安装Kafka官方说法，Java环境推荐Java8。

Kafka需要Zookeeper保存集群的元数据信息和消费者信息。Kafka一般会自带Zookeeper，但是从稳定性考虑，应该使用单独的Zookeeper，而且构建Zookeeper集群。

###  下载和安装Kafka 

在http://kafka.apache.org/downloads上寻找合适的版本下载，我们这里选用的是kafka_2.11-0.10.1.1，下载完成后解压到本地目录。

###  运行 

启动Zookeeper

进入Kafka目录下的bin\windows

执行kafka-server-start.bat ../../config/server.properties，出现以下画面表示成功

Linux下与此类似，进入bin后，执行对应的sh文件即可

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsHmNSZT.jpg) 

###  基本的操作和管理 

 ##列出所有主题 

kafka-topics.bat --zookeeper localhost:2181/kafka --list

 ##列出所有主题的详细信息 

kafka-topics.bat --zookeeper localhost:2181/kafka --describe

 ##创建主题 主题名 my-topic，1副本，8分区 

kafka-topics.bat --zookeeper localhost:2181/kafka --create --topic my-topic --replication-factor 1 --partitions 8

 ##增加分区，注意：分区无法被删除 

kafka-topics.bat --zookeeper localhost:2181/kafka --alter --topic my-topic --partitions 16

 ##删除主题 

kafka-topics.bat --zookeeper localhost:2181/kafka --delete --topic my-topic

 ##列出消费者群组（仅Linux） 

kafka-topics.sh --new-consumer --bootstrap-server localhost:9092/kafka --list

 ##列出消费者群组详细信息（仅Linux） 

kafka-topics.sh --new-consumer --bootstrap-server localhost:9092/kafka --describe --group 群组名

##  Broker配置 

配置文件放在Kafka目录下的config目录中，主要是server.properties文件

###  常规配置 

####  *broker.id 

在单机时无需修改，但在集群下部署时往往需要修改。它是个每一个broker在集群中的唯一表示，要求是正数。当该服务器的IP地址发生改变时，broker.id没有变化，则不会影响consumers的消息情况

####  *listeners 

监听列表(以逗号分隔 不同的协议(如plaintext,trace,ssl、不同的IP和端口)),hostname如果设置为0.0.0.0则绑定所有的网卡地址；如果hostname为空则绑定默认的网卡。如果
没有配置则默认为java.net.InetAddress.getCanonicalHostName()。

如：PLAINTEXT://myhost:9092,TRACE://:9091或 PLAINTEXT://0.0.0.0:9092,

####  *zookeeper.connect 

zookeeper集群的地址，可以是多个，多个之间用逗号分割

####  *log.dirs 

Kafka把所有的消息都保存在磁盘上，存放这些数据的目录通过log.dirs指定。

####  *num.recovery.threads.per.data.dir 

每数据目录用于日志恢复启动和关闭时的线程数量。因为这些线程只是服务器启动和关闭时会用到。所以完全可以设置大量的线程来达到并行操作的目的。注意，这个参数指的是每个日志目录的线程数，比如本参数设置为8，而log.dirs设置为了三个路径，则总共会启动24个线程。

####  *auto.create.topics.enable 

是否允许自动创建主题。如果设为true，那么produce，consume或者fetch metadata一个不存在的主题时，就会自动创建。缺省为true。

###  主题配置 

新建主题的默认参数

####  *num.partitions 

每个新建主题的分区个数。这个参数一般要评估，比如，每秒钟要写入和读取1GB数据，如果现在每个消费者每秒钟可以处理50MB的数据，那么需要20个分区，这样就可以让20个消费者同时读取这些分区，从而达到设计目标。

####  *log.retention.hours 

日志保存时间，默认为7天（168小时）。超过这个时间会清理数据。bytes和minutes无论哪个先达到都会触发。与此类似还有log.retention.minutes和log.retention.ms，都设置的话，优先使用具有最小值的那个。

####  *log.retention.bytes 

topic每个分区的最大文件大小，一个topic的大小限制 = 分区数*log.retention.bytes。-1没有大小限制。log.retention.bytes和log.retention.minutes任意一个达到要求，都会执行删除。

####  *log.segment.bytes 	

分区的日志存放在某个目录下诸多文件中，这些文件将分区的日志切分成一段一段的，我们称为日志片段。这个属性就是每个文件的最大尺寸；当尺寸达到这个数值时，就会关闭当前文件，并创建新文件。被关闭的文件就开始等待过期。默认为1G。

如果一个主题每天只接受100MB的消息，那么根据默认设置，需要10天才能填满一个文件。而且因为日志片段在关闭之前，消息是不会过期的，所以如果log.retention.hours保持默认值的话，那么这个日志片段需要17天才过期。因为关闭日志片段需要10天，等待过期又需要7天。

####  *log.segment.ms 

作用和log.segment.bytes类似，只不过判断依据是时间。同样的，两个参数，以先到的为准。这个参数默认是不开启的。

####  *message.max.bytes 	

表示一个服务器能够接收处理的消息的最大字节数，注意这个值producer和consumer必须设置一致，且不要大于fetch.message.max.bytes属性的值。该值默认是1000000字节，大概900KB~1MB。

##  硬件配置对Kafka性能的影响 

###  磁盘吞吐量/磁盘容量 

磁盘吞吐量会影响生产者的性能。因为生产者的消息必须被提交到服务器保存，大多数的客户端都会一直等待，直到至少有一个服务器确认消息已经成功提交为止。也就是说，磁盘写入速度越快，生成消息的延迟就越低。

磁盘容量的大小，则主要看需要保存的消息数量。如果每天收到1TB的数据，并保留7天，那么磁盘就需要7TB的数据。

###  内存 

Kafka本身并不需要太大内存，内存则主要是影响消费者性能。在大多数业务情况下，消费者消费的数据一般会从内存中获取，这比在磁盘上读取肯定要快的多。

###  网络 

网络吞吐量决定了Kafka能够处理的最大数据流量。

###  CPU 

Kafka对cpu的要求不高，主要是用在对消息解压和压缩上。所以cpu的性能不是在使用Kafka的首要考虑因素。

#  Kafka的集群 

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpshnyqIe.jpg) 

##  为何需要Kafka集群 

本地开发，一台Kafka足够使用。在实际生产中，集群可以跨服务器进行负载均衡，再则可以使用复制功能来避免单独故障造成的数据丢失。同时集群可以提供高可用性。

##  如何估算Kafka集群中Broker的数量 

要估量以下几个因素：

需要多少磁盘空间保留数据，和每个broker上有多少空间可以用。比如，如果一个集群有10TB的数据需要保留，而每个broker可以存储2TB，那么至少需要5个broker。如果启用了数据复制，则还需要一倍的空间，那么这个集群需要10个broker。

集群处理请求的能力。如果因为磁盘吞吐量和内存不足造成性能问题，可以通过扩展broker来解决。

##  Broker如何加入Kafka集群 

非常简单，只需要两个参数。第一，配置zookeeper.connect，第二，为新增的broker设置一个集群内的唯一性id。

#  第一个Kafka程序  

##  创建我们的主题 

kafka-topics.bat --zookeeper localhost:2181/kafka --create --topic hello-kafka --replication-factor 1 --partitions 4

##  生产者发送消息 

####  *必选属性 

创建生产者对象时有三个属性必须指定。

##### bootstrap.servers

该属性指定broker的地址清单，地址的格式为host：port。清单里不需要包含所有的broker地址，生产者会从给定的broker里查询其他broker的信息。不过最少提供2个broker的信息，一旦其中一个宕机，生产者仍能连接到集群上。

##### key.serializer

生产者接口允许使用参数化类型，可以把Java对象作为键和值传broker，但是broker希望收到的消息的键和值都是字节数组，所以，必须提供将对象序列化成字节数组的序列化器。key.serializer必须设置为实现org.apache.kafka.common.serialization.Serializer的接口类，Kafka的客户端默认提供了ByteArraySerializer,IntegerSerializer, StringSerializer，也可以实现自定义的序列化器。

##### value.serializer

同 key.serializer。

参见代码，模块kafka-no-spring下包hellokafka中

##  消费者接受消息 

####  *必选参数 

bootstrap.servers、key.serializer、value.serializer含义同生产者

##### group.id

并非完全必需，它指定了消费者属于哪一个群组，但是创建不属于任何一个群组的消费者并没有问题。

参见代码，模块kafka-no-spring下包hellokafka中

#  Kafka的生产者 

##  生产者发送消息的基本流程 

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsxh20qz.jpg) 

从创建一个ProducerRecord 对象开始， Producer Record 对象需要包含目标主题和要发送的内容。我们还可以指定键或分区。在发送ProducerReco rd 对象时，生产者要先把键和值对象序列化成字节数组，这样它们才能够在网络上传输。

接下来，数据被传给分区器。如果之前在Producer Record 对象里指定了分区，那么分区器就不会再做任何事情，直接把指定的分区返回。如果没有指定分区，那么分区器会根据Producer Record对象的键来选择一个分区。选好分区以后，生产者就知道该往哪个主题和分区发送这条记录了。紧接着，这条记录被添加到一个记录批次里，这个批次里的所有消息会被发送到相同的主题和分区上。有一个独立的线程负责把这些记录批次发送到相应的broker 上。

服务器在收到这些消息时会返回一个响应。如果消息成功写入Kafka ，就返回一个RecordMetaData 对象，它包含了主题和分区信息，以及记录在分区里的偏移量。如果写入失败， 则会返回一个错误。生产者在收到错误之后会尝试重新发送消息，几次之后如果还是失败，就返回错误信息。

##  使用Kafka生产者 

###   三种发送方式 

我们通过生成者的send方法进行发送。send方法会返回一个包含RecordMetadata的Future对象。RecordMetadata里包含了目标主题，分区信息和消息的偏移量。

####  *发送并忘记 

忽略send方法的返回值，不做任何处理。大多数情况下，消息会正常到达，而且生产者会自动重试，但有时会丢失消息。

####  *同步非阻塞发送 

获得send方法返回的Future对象，在合适的时候调用Future的get方法。参见代码，模块kafka-no-spring下包sendtype中。

####  *异步发送 

实现接口org.apache.kafka.clients.producer.Callback，然后将实现类的实例作为参数传递给send方法。参见代码，模块kafka-no-spring下包sendtype中。

###  多线程下的生产者 

KafkaProducer的实现是线程安全的，所以我们可以在多线程的环境下，安全的使用KafkaProducer的实例，如何节约资源的使用呢？参见代码，模块kafka-no-spring下包concurrent中

###   更多发送配置   

生产者有很多属性可以设置，大部分都有合理的默认值，无需调整。有些参数可能对内存使用，性能和可靠性方面有较大影响。可以参考org.apache.kafka.clients.producer包下的ProducerConfig类。

##### acks：

指定了必须要有多少个分区副本收到消息，生产者才会认为写入消息是成功的，这个参数对消息丢失的可能性有重大影响。

acks=0：生产者在写入消息之前不会等待任何来自服务器的响应，容易丢消息，但是吞吐量高。

acks=1：只要集群的首领节点收到消息，生产者会收到来自服务器的成功响应。如果消息无法到达首领节点（比如首领节点崩溃，新首领没有选举出来），生产者会收到一个错误响应，为了避免数据丢失，生产者会重发消息。不过，如果一个没有收到消息的节点成为新首领，消息还是会丢失。默认使用这个配置。

acks=all：只有当所有参与复制的节点都收到消息，生产者才会收到一个来自服务器的成功响应。延迟高。

##### buffer.memory

设置生产者内存缓冲区的大小，生产者用它缓冲要发送到服务器的消息。如果数据产生速度大于向broker发送的速度，导致生产者空间不足，producer会阻塞或者抛出异常。缺省33554432 (32M)

##### max.block.ms

指定了在调用send()方法或者使用partitionsFor()方法获取元数据时生产者的阻塞时间。当生产者的发送缓冲区已满，或者没有可用的元数据时，这些方法就会阻塞。在阻塞时间达到max.block.ms时，生产者会抛出超时异常。缺省60000ms

##### retries

发送失败时，指定生产者可以重发消息的次数。默认情况下，生产者在每次重试之间等待100ms，可以通过参数retry.backoff.ms参数来改变这个时间间隔。缺省0

##### receive.buffer.bytes和send.buffer.bytes

指定TCP socket接受和发送数据包的缓存区大小。如果它们被设置为-1，则使用操作系统的默认值。如果生产者或消费者处在不同的数据中心，那么可以适当增大这些值，因为跨数据中心的网络一般都有比较高的延迟和比较低的带宽。缺省102400

##### batch.size

当多个消息被发送同一个分区时，生产者会把它们放在同一个批次里。该参数指定了一个批次可以使用的内存大小，按照字节数计算。当批次内存被填满后，批次里的所有消息会被发送出去。但是生产者不一定都会等到批次被填满才发送，半满甚至只包含一个消息的批次也有可能被发送。缺省16384(16k)

##### linger.ms

指定了生产者在发送批次前等待更多消息加入批次的时间。它和batch.size以先到者为先。也就是说，一旦我们获得消息的数量够batch.size的数量了，他将会立即发送而不顾这项设置，然而如果我们获得消息字节数比batch.size设置要小的多，我们需要“linger”特定的时间以获取更多的消息。这个设置默认为0，即没有延迟。设定linger.ms=5，例如，将会减少请求数目，但是同时会增加5ms的延迟，但也会提升消息的吞吐量。

##### compression.type

producer用于压缩数据的压缩类型。默认是无压缩。正确的选项值是none、gzip、snappy。压缩最好用于批量处理，批量处理消息越多，压缩性能越好。snappy占用cpu少，提供较好的性能和可观的压缩比，如果比较关注性能和网络带宽，用这个。如果带宽紧张，用gzip，会占用较多的cpu，但提供更高的压缩比。

##### client.id	

当向server发出请求时，这个字符串会发送给server。目的是能够追踪请求源头，以此来允许ip/port许可列表之外的一些应用可以发送信息。这项应用可以设置任意字符串，因为没有任何功能性的目的，除了记录和跟踪。

##### max.in.flight.requests.per.connection	

指定了生产者在接收到服务器响应之前可以发送多个消息，值越高，占用的内存越大，当然也可以提升吞吐量。发生错误时，可能会造成数据的发送顺序改变,默认是5 (修改）。

如果需要保证消息在一个分区上的严格顺序，这个值应该设为1。不过这样会严重影响生产者的吞吐量。

##### request.timeout.ms

客户端将等待请求的响应的最大时间,如果在这个时间内没有收到响应，客户端将重发请求;超过重试次数将抛异常

##### metadata.fetch.timeout.ms

是指我们所获取的一些元数据的第一个时间数据。元数据包含：topic，host，partitions。此项配置是指当等待元数据fetch成功完成所需要的时间，否则会跑出异常给客户端

##### timeout.ms

此配置选项控制broker等待副本确认的最大时间。如果确认的请求数目在此时间内没有实现，则会返回一个错误。这个超时限制是以server端度量的，没有包含请求的网络延迟。这个参数和acks的配置相匹配。

##### max.request.size

控制生产者发送请求最大大小。假设这个值为1M，如果一个请求里只有一个消息，那这个消息不能大于1M，如果一次请求是一个批次，该批次包含了1000条消息，那么每个消息不能大于1KB。注意：broker具有自己对消息记录尺寸的覆盖，如果这个尺寸小于生产者的这个设置，会导致消息被拒绝。

####  *顺序保证 

Kafka 可以保证同一个分区里的消息是有序的。也就是说，如果生产者一定的顺序发送消息， broker 就会按照这个顺序把它们写入分区，消费者也会按照同样的顺序读取它们。在某些情况下， 顺序是非常重要的。例如，往一个账户存入100 元再取出来，这个与先取钱再存钱是截然不同的！不过，有些场景对顺序不是很敏感。

如果把retires设为非零整数，同时把max.in.flight.request.per.connection设为比1 大的数，那么，如果第一个批次消息写入失败，而第二个批次写入成功， broker 会重试写入第一个批次。如果此时第一个批次也写入成功，那么两个批次的顺序就反过来了。

一般来说，如果某些场景要求消息是有序的，那么消息是否写入成功也是很关键的，所以不建议把retires设为0 。可以把max.in.flight.request.per.connection 设为1，这样在生产者尝试发送第一批消息时，就不会有其他的消息发送给broker 。不过这样会严重影响生产者的吞吐量，所以只有在对消息的顺序有严格要求的情况下才能这么做。

##  序列化 

创建生产者对象必须指定序列化器，默认的序列化器并不能满足我们所有的场景。我们完全可以自定义序列化器。只要实现org.apache.kafka.common.serialization.Serializer接口即可。

如何实现，看模块kafka-no-spring下包selfserial中代码。

###  自定义序列化需要考虑的问题 

自定义序列化容易导致程序的脆弱性。举例，在我们上面的实现里，我们有多种类型的消费者，每个消费者对实体字段都有各自的需求，比如，有的将字段变更为long型，有的会增加字段，这样会出现新旧消息的兼容性问题。特别是在系统升级的时候，经常会出现一部分系统升级，其余系统被迫跟着升级的情况。

解决这个问题，可以考虑使用自带格式描述以及语言无关的序列化框架。比如Protobuf，或者Kafka官方推荐的Apache Avro。

Avro会使用一个JSON文件作为schema来描述数据，Avro在读写时会用到这个schema，可以把这个schema内嵌在数据文件中。这样，不管数据格式如何变动，消费者都知道如何处理数据。

但是内嵌的消息，自带格式，会导致消息的大小不必要的增大，消耗了资源。我们可以使用schema注册表机制，将所有写入的数据用到的schema保存在注册表中，然后在消息中引用schema的标识符，而读取的数据的消费者程序使用这个标识符从注册表中拉取schema来反序列化记录。

 注意 ：Kafka本身并不提供schema注册表，需要借助第三方，现在已经有很多的开源实现，比如Confluent Schema Registry，可以从GitHub上获取。如何使用参考如下网址：

https://cloud.tencent.com/developer/article/1336568

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsZwGG9T.jpg) 

##  分区 

我们在新增ProducerRecord对象中可以看到，ProducerRecord包含了目标主题，键和值，Kafka的消息都是一个个的键值对。键可以设置为默认的null。

键的主要用途有两个：一，用来决定消息被写往主题的哪个分区，拥有相同键的消息将被写往同一个分区，二，还可以作为消息的附加消息。

如果键值为null，并且使用默认的分区器，分区器使用轮询算法将消息均衡地分布到各个分区上。

如果键不为空，并且使用默认的分区器，Kafka对键进行散列（Kafka自定义的散列算法，具体算法原理不知），然后根据散列值把消息映射到特定的分区上。很明显，同一个键总是被映射到同一个分区。但是只有不改变主题分区数量的情况下，键和分区之间的映射才能保持不变，一旦增加了新的分区，就无法保证了，所以如果要使用键来映射分区，那就要在创建主题的时候把分区规划好，而且永远不要增加新分区。

###  自定义分区器 

某些情况下，数据特性决定了需要进行特殊分区，比如电商业务，北京的业务量明显比较大，占据了总业务量的20%，我们需要对北京的订单进行单独分区处理，默认的散列分区算法不合适了， 我们就可以自定义分区算法，对北京的订单单独处理，其他地区沿用散列分区算法。或者某些情况下，我们用value来进行分区。

具体实现，先创建一个4分区的主题，然后观察模块kafka-no-spring下包SelfPartitionProducer中代码。

#  Kafka的消费者 

##  消费者和消费者群组、分区再均衡 

消费者的含义，同一般消息中间件中消费者的概念。在高并发的情况下，生产者产生消息的速度是远大于消费者消费的速度，单个消费者很可能会负担不起，此时有必要对消费者进行横向伸缩，于是我们可以使用多个消费者从同一个主题读取消息，对消息进行分流。

###  消费者群组 

Kafka里消费者从属于消费者群组，一个群组里的消费者订阅的都是同一个主题，每个消费者接收主题一部分分区的消息。

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsll2nSe.jpg) 

如上图，主题T有4个分区，群组中只有一个消费者，则该消费者将收到主题T1全部4个分区的消息。

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsN7x6Az.jpg) 

如上图，在群组中增加一个消费者2，那么每个消费者将分别从两个分区接收消息，上图中就表现为消费者1接收分区1和分区3的消息，消费者2接收分区2和分区4的消息。

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsFi8PjU.jpg) 

如上图，在群组中有4个消费者，那么每个消费者将分别从1个分区接收消息。

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wps7MDA2e.jpg) 

但是，当我们增加更多的消费者，超过了主题的分区数量，就会有一部分的消费者被闲置，不会接收到任何消息。

往消费者群组里增加消费者是进行横向伸缩能力的主要方式。所以我们有必要为主题设定合适规模的分区，在负载均衡的时候可以加入更多的消费者。但是要记住，一个群组里消费者数量超过了主题的分区数量，多出来的消费者是没有用处的。

如果是多个应用程序，需要从同一个主题中读取数据，只要保证每个应用程序有自己的消费者群组就行了。如下图所示：

![img](image/13.%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/wpsR9rmLz.jpg) 

具体实现，先建立一个2分区的主题，看模块kafka-no-spring下包consumergroup中代码。

###  分区再均衡 

当消费者群组里的消费者发生变化，或者主题里的分区发生了变化，都会导致再均衡现象的发生。从前面的知识中，我们知道，Kafka中，存在着消费者对分区所有权的关系，

这样无论是消费者变化，比如增加了消费者，新消费者会读取原本由其他消费者读取的分区，消费者减少，原本由它负责的分区要由其他消费者来读取，增加了分区，哪个消费者来读取这个新增的分区，这些行为，都会导致分区所有权的变化，这种变化就被称为 再均衡 。

再均衡对Kafka很重要，这是消费者群组带来高可用性和伸缩性的关键所在。不过一般情况下，尽量减少再均衡，因为再均衡期间，消费者是无法读取消息的，会造成整个群组一小段时间的不可用。

消费者通过向称为群组协调器的broker（不同的群组有不同的协调器）发送心跳来维持它和群组的从属关系以及对分区的所有权关系。如果消费者长时间不发送心跳，群组协调器认为它已经死亡，就会触发一次再均衡。

在0.10.1及以后的版本中，心跳由单独的线程负责，相关的控制参数为max.poll.interval.ms。

####  *消费者分区分配的过程 

消费者要加入群组时，会向群组协调器发送一个JoinGroup请求，第一个加入群主的消费者成为群主，群主会获得群组的成员列表，并负责给每一个消费者分配分区。分配完毕后，群组把分配情况发送给群组协调器，协调器再把这些信息发送给所有的消费者，每个消费者只能看到自己的分配信息，只有群主知道群组里所有消费者的分配信息。这个过程在每次再均衡时都会发生。

##  使用Kafka消费者 

###  订阅 

创建消费者后，使用subscribe()方法订阅主题，这个方法接受一个主题列表为参数，也可以接受一个正则表达式为参数；正则表达式同样也匹配多个主题。如果新创建了新主题，并且主题名字和正则表达式匹配，那么会立即触发一次再均衡，消费者就可以读取新添加的主题。比如，要订阅所有和test相关的主题，可以subscribe(“tets.*”)

###  轮询 

为了不断的获取消息，我们要在循环中不断的进行轮询，也就是不停调用poll方法。

poll方法的参数为超时时间，控制poll方法的阻塞时间，它会让消费者在指定的毫秒数内一直等待broker返回数据。poll方法将会返回一个记录（消息）列表，每一条记录都包含了记录所属的主题信息，记录所在分区信息，记录在分区里的偏移量，以及记录的键值对。

poll方法不仅仅只是获取数据，在新消费者第一次调用时，它会负责查找群组，加入群组，接受分配的分区。如果发生了再均衡，整个过程也是在轮询期间进行的。

###  多线程下的消费者 

KafkaConsumer的实现 不是 线程安全的，所以我们在多线程的环境下，使用KafkaConsumer的实例要小心，应该每个消费数据的线程拥有自己的KafkaConsumer实例，如何使用？参见代码，模块kafka-no-spring下包concurrent中

###  消费者配置   

消费者有很多属性可以设置，大部分都有合理的默认值，无需调整。有些参数可能对内存使用，性能和可靠性方面有较大影响。可以参考org.apache.kafka.clients.consumer包下ConsumerConfig类。

##### fetch.min.bytes	

每次fetch请求时，server应该返回的最小字节数。如果没有足够的数据返回，请求会等待，直到足够的数据才会返回。缺省为1个字节。多消费者下，可以设大这个值，以降低broker的工作负载

##### fetch.wait.max.ms	

如果没有足够的数据能够满足fetch.min.bytes，则此项配置是指在应答fetch请求之前，server会阻塞的最大时间。缺省为500个毫秒。和上面的fetch.min.bytes结合起来，要么满足数据的大小，要么满足时间，就看哪个条件先满足。

##### max.partition.fetch.bytes

指定了服务器从每个分区里返回给消费者的最大字节数，默认1MB。假设一个主题有20个分区和5个消费者，那么每个消费者至少要有4MB的可用内存来接收记录，而且一旦有消费者崩溃，这个内存还需更大。注意，这个参数要比服务器的message.max.bytes更大，否则消费者可能无法读取消息。

##### session.timeout.ms

如果consumer在这段时间内没有发送心跳信息，则它会被认为挂掉了。默认3秒。

##### auto.offset.reset	

消费者在读取一个没有偏移量的分区或者偏移量无效的情况下，如何处理。默认值是latest，从最新的记录开始读取，另一个值是earliest，表示消费者从起始位置读取分区的记录。

 注意 ：默认值是latest，意思是说，在偏移量无效的情况下，消费者将从最新的记录开始读取数据（ 在消费者启动之后生成的记录 ），可以先启动生产者，再启动消费者，观察到这种情况。观察代码，在模块kafka-no-spring下包hellokafka中。

##### enable .auto.commit	

默认值true，表明消费者是否自动提交偏移。为了尽量避免重复数据和数据丢失，可以改为false，自行控制何时提交。

##### partition.assignment.strategy

分区分配给消费者的策略。系统提供两种策略。默认为Range。允许自定义策略。

###### **Range**

把主题的连续分区分配给消费者。例如，有主题T1和T2，各有3个分区，消费者C1和C2，则 可能 的分配形式为：

C1: T1(0，1),T2(0,，1)

C2: T1(2),T2(2)

###### **RoundRobin**

把主题的分区循环分配给消费者。例如，有主题T1和T2，各有3个分区，消费者C1和C2，则 可能 的分配形式为：

C1: T1(0，2),T2(1)

C2: T1(1),T2(0，2)

###### **自定义策略**

extends 类AbstractPartitionAssignor，然后在消费者端增加参数：

properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, 类.class.getName());即可。

##### client.id	

当向server发出请求时，这个字符串会发送给server。目的是能够追踪请求源头，以此来允许ip/port许可列表之外的一些应用可以发送信息。这项应用可以设置任意字符串，因为没有任何功能性的目的，除了记录和跟踪。

##### max.poll.records

控制每次poll方法返回的的记录数量。

##### receive.buffer.bytes和send.buffer.bytes

指定TCP socket接受和发送数据包的缓存区大小。如果它们被设置为-1，则使用操作系统的默认值。如果生产者或消费者处在不同的数据中心，那么可以适当增大这些值，因为跨数据中心的网络一般都有比较高的延迟和比较低的带宽。

 