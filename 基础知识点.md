### 基础知识点

## java基础

1.String,stringbuffer,stringbuilder区别

StringBuilder是线程不安全的，StringBuffer是用synchronized修饰的，string是不可变的，前面两个是可变的。string的+是创建了StringBuilder对象进行append操作，然后将拼接好的对象用toString方法处理成String对象。

。

String s = new String("hello")可能创建两个对象也可能创建一个对象，如果静态区中有hello world字符串常量对象的化，则仅在堆中创建一个对象，如果静态区没有，则堆上和静态区都需要创建对象。

s是放在栈上，用new创建出来的字符串对象放在堆上，hello字面量放在方法区上。

使用字面量时只创建一个常量池中的常量，使用 new 时如果常量池中没有该值就会在常量池中新创建，再在堆中创建一个对象引用常量池中常量。因此 `String a = "a" + new String("b")` 会创建四个对象，常量池中的 a 和 b，堆中的 b 和堆中的 ab。常量和常量拼接仍是常量，结果在常量池，只要有变量参与拼接结果就是变量，存在堆，所以ab在堆。

### 字符串拼接的方式有哪些？

① 直接用 `+` ，底层用 StringBuilder 实现。只适用小数量，如果在循环中使用 `+` 拼接，相当于不断创建新的 StringBuilder 对象再转换成 String 对象，效率极差。

② 使用 String 的 concat 方法，该方法中使用 `Arrays.copyOf` 创建一个新的字符数组 buf 并将当前字符串 value 数组的值拷贝到 buf 中，buf 长度 = 当前字符串长度 + 拼接字符串长度。之后调用 `getChars` 方法使用 `System.arraycopy` 将拼接字符串的值也拷贝到 buf 数组，最后用 buf 作为构造参数 new 一个新的 String 对象返回。效率稍高于直接使用 `+`。

③ 使用 StringBuilder 或 StringBuffer，两者的 `append` 方法都继承自 AbstractStringBuilder，该方法首先使用 `Arrays.copyOf` 确定新的字符数组容量，再调用 `getChars` 方法使用 `System.arraycopy` 将新的值追加到数组中。StringBuilder 是 JDK5 引入的，效率高但线程不安全。StringBuffer 使用 synchronized 保证线程安全。

2.重写equals方法也要重写hashcode方法，不然在set中会出现两个相同的值

3.避免hashcode攻击：限制post和get参数个数，限制post数据包大小，应用程序防火墙

4.反射：在运行时动态获取一个类的方法和属性，调用一个对象的方法和属性

5.获取class方法：

- class.getClass()
- Class.forname()会对类初始化，会执行静态代码块，使用调用者的类加载器
- ClassLoader.loadClass()不会初始化，只会装载或链接，只有newInstance时才会执行静态代码块，可指定类加载器。

6.jdk1.8新特性：lambda表达式，可以将方法当做参数传递进去。接口中可以定义静态方法和默认的实现方法。

7.static和final区别：

- static修饰变量类加载时候被初始化，所有类共享
- static修饰方法，类加载时候就存在，不依赖任何实例
- static修饰代码块，类加载后就会执行
- final修饰变量，编译器常量加载时完成初始化，只能是基本类型。运行时常量，基本类型和引用类型
- final修饰方法：不能被继承，不能被修改
- final修饰类：不能被继承

8.协程：在子程序内部中断，转而去执行别的子程序，在适当的时候再返回来执行。yIeld

9.同步异步指获取通信结果的方式是主动还是被动。阻塞非阻塞指等待结果的时候线程的状态。

10.ThreadLocal内部是一个map,为每个使用该变量的线程提供独立的变量副本。每个线程独立的更改自己的副本，对其他线程不影响。

11.finalize,finalization,finally

- finalize在垃圾回收时候回收JNI的内存
- finally

12.Object有哪些方法：hashcode(),equals(),toString(),getClass(),wait,notify,notifyAll,finalize.

13.equals和==

- 基本数据类型==是比较实际值
- 复合数据类型==是比较内存地址
- 复合类型重写了equals比较内容，否则比较地址
- StringBuffer 和 StringBuilder 特殊，==和 equal 都是比较地址
- 比较两个包装类数值要用 `equals` ，而不能用 `==` 。

总结：

 == 的作用：
　　基本类型：比较值是否相等
　　引用类型：比较内存地址值是否相等

equals 的作用:
　　引用类型：默认情况下，比较内存地址值是否相等。可以按照需求逻辑，重写对象的equals方法。

![image-20200802095807112](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200802095807112.png)

![image-20200802095823612](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200802095823612.png)



HashMap重写equals和hashcode

两个对象==相等，则其hashcode一定相等，反之不一定成立。

两个对象equals相等，则其hashcode一定相等，反之不一定成立。

![image-20200802100209748](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200802100209748.png)

这里重写的hashcode是一样的，所以还是put进去了。所以还需要重新equals方法。其实是有这样一个规定，如果hahscode一样时，则还需要继续调用equals方式看看对象是否相等。

可以看到如果hashcode不一样就直接认为是不一样的对象，不需要再去equal比较，更加节省时间。



13.序列化：要实现serializable接口。反序列化完全基于字节，不需要依赖构造方法，但是要有序列化对象时的class文件。static修饰的不会被序列化，因为它不属于对象。对象的类名，属性会被序列化，方法不会被序列化。当一个对象的实例变量引用其他对象，序列化该对象时也会把引用对象进行序列化，所以可以实现深拷贝。

14.comparable只能根据一个字段进行排序，不能根据需要选择对象字段来对对象进行排序。comparator接口可以实现两个对象的特定字段的比较。

15.接口和抽象类区别：

- 抽象类可以有构造方法，接口没有
- 抽象类中可以有普通成员变量，接口中不能有，只有静态成员变量
- 抽象类中可以有非抽象的方法，接口中都是抽象方法
- 抽象类方法可以是任意类型，接口中只能是public类型
- 抽象类中可以包含静态方法，接口中不能有静态方法。

16.泛型：

泛型指参数化类型，就是将类型由原来的具体的类型参数化，然后再调用的时候传入具体的类型。泛型的本质是为了将类型参数化。这种参数类型可以用在类，接口和方法上，分别称为泛型类，泛型接口，泛型方法。

在编译之后程序会采取去泛型化的措施。也就是说Java中的泛型，只在编译阶段有效。在编译过程中，正确检验泛型结果后，会将泛型的相关信息擦出，并且在对象进入和离开方法的边界处添加类型检查和类型转换的方法。也就是说，泛型信息不会进入到运行时阶段。

泛型类，是在实例化类的时候指明泛型的具体类型；泛型方法，是在调用方法的时候指明泛型的具体类型 。

17.泛型擦除

泛型用于编译阶段，编译后的字节码不包含泛型类型信息。因为虚拟机没有泛型类型对象，所有对象都属于普通类。定义一个泛型类型，会自动提供一个对应的原始类型。



如果两个对象相同（equals方法返回true)，那么他们的hashCode值一定相同

如果两个对象的hashcode相同，他们并不一定相同

equals必须满足的特性：自反性，对称性，传递性，一致性。

重载的返回类型可以不同，重写的返回类型相同

类的加载过程：加载，连接（验证，准备，解析）和初始化。加载就是通过字节数组将.class文件读入内存，并生成class对象。验证就是检查字节码是否符合规范。准备是为静态变量分配内存并设置初始值。解析是将符号引用转换为直接引用。

初始化阶段：

- 如果类存在直接父类，并且父类没有被初始化，就先初始化父类。
- 如果类中存在初始化语句，就以此执行初始化语句。

双亲委派模型：任何一个类，都需要由加载它的类加载器和这个类本身来共同确定其在jvm中的唯一性。为了保证相同的class文件，在使用的时候是相同的对象，所以采用双亲委派模型。

1. 启动类加载器（Bootstrap ClassLoader）：C++实现，在java里无法获取，**负责加载/lib**下的类。
2. 扩展类加载器（Extension ClassLoader）： Java实现，可以在java里获取，**负责加载/lib/ext**下的类。
3. 系统类加载器/应用程序类加载器（Application ClassLoader）：是与我们接触对多的类加载器，我们写的代码默认就是由它来加载，ClassLoader.getSystemClassLoader返回的就是它。
4. 双亲委派的实现就是一个递归方法，如果父类加载器不为空，就调用父类的加载方法。

### 3.1、为什么需要破坏双亲委派？

因为在某些情况下父类加载器需要委托子类加载器去加载class文件。受到加载范围的限制，父类加载器无法加载到需要的文件，以Driver接口为例，由于Driver接口定义在jdk当中的，而其实现由各个数据库的服务商来提供，比如mysql的就写了`MySQL Connector`，那么问题就来了，DriverManager（也由jdk提供）要加载各个实现了Driver接口的实现类，然后进行管理，但是DriverManager由启动类加载器加载，只能记载JAVA_HOME的lib下文件，而其实现是由服务商提供的，由系统类加载器加载，这个时候就需要启动类加载器来委托子类来加载Driver实现，从而破坏了双亲委派，这里仅仅是举了破坏双亲委派的其中一个情况。

当我们使用pop方法弹出栈的对象的时候，该对象不会被当做垃圾回收，即使使用的栈的程序不再引用这些对象，因为栈内部维护着对这些对象的过期引用。



try中有return语句，这个返回值会先被记录下，等到finally中的代码执行完之后才会返回。

20.泛型擦除



## 并发

1.Synchronized的原理

在 Java 中，关键字 synchronized可以保证在同一个时刻，只有一个线程可以执行某个方法或者某个代码块(主要是对方法或者代码块中存在共享数据的操作)，同时我们还应该注意到synchronized另外一个重要的作用，synchronized可保证一个线程的变化(主要是共享数据的变化)被其他线程所看到（保证可见性，完全可以替代Volatile功能），这点确实也是很重要的。

- 修饰实例方法，作用于当前实例加锁，进入同步代码前要获得当前实例的锁
- 修饰静态方法，作用于当前类对象加锁，进入同步代码前要获得当前类对象的锁
- 修饰代码块，指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。，我们还可以使用this对象(代表当前实例)或者当前类的class对象作为锁

![image-20200725092730395](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200725092730395.png)

![image-20200725093036986](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200725093036986.png)

![image-20200725093403080](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200725093403080.png)

Sychronized代码块的底层原理：

![image-20200725093835655](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200725093835655.png)

![image-20200725094040020](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200725094040020.png)

![image-20200725094120021](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200725094120021.png)

偏向锁：为了解决同一个线程多次获取锁，减少同一个线程获取锁的代价（CAS)，偏向锁的核心思想是，如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word 的结构也变为偏向锁结构，当这个线程再次请求锁时，无需再做任何同步操作，即获取锁的过程，这样就省去了大量有关锁申请的操作，从而也就提供程序的性能。

轻量级锁：倘若偏向锁失败，虚拟机并不会立即升级为重量级锁，它还会尝试使用一种称为轻量级锁的优化手段(1.6之后加入的)，此时Mark Word 的结构也变为轻量级锁的结构。轻量级锁能够提升程序性能的依据是“对绝大部分的锁，在整个同步周期内都不存在竞争”，注意这是经验数据。需要了解的是，轻量级锁所适应的场景是线程交替执行同步块的场合，如果存在同一时间访问同一锁的场合，就会导致轻量级锁膨胀为重量级锁。

自旋锁：轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。这是基于在大多数情况下，线程持有锁的时间都不会太长，如果直接挂起操作系统层面的线程可能会得不偿失，毕竟操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，因此自旋锁会假设在不久将来，当前的线程可以获得锁，因此虚拟机会让当前想要获取锁的线程做几个空循环(这也是称为自旋的原因)，一般不会太久，可能是50个循环或100循环，在经过若干次循环后，如果得到锁，就顺利进入临界区。如果还不能获得锁，那就会将线程在操作系统层面挂起，这就是自旋锁的优化方式，这种方式确实也是可以提升效率的。最后没办法也就只能升级为重量级锁了。
![image-20200725095658225](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200725095658225.png)

事实上线程的中断操作对于正在等待获取的锁对象的synchronized方法或者代码块并不起作用，也就是对于synchronized来说，如果一个线程在等待锁，那么结果只有两种，要么它获得这把锁继续执行，要么它就保存等待，即使调用中断线程的方法，也不会生效。



Voliate关键字：

Volatile 是**轻量级的 synchronized**，它在多处理器开发中保证了共享变量的“可见性”。可见性的意思是当一个线程修改一个共享变量时，另外一个线程能读到这个修改的值。Volatile 变量修饰符如果使用**恰当**的话，它比 synchronized 的**使用和执行成本会更低**，因为它不会引起线程上下文的切换和调度。

有voliate修饰的变量进行写操作时会使用lock指令，lock功能：

- 将当前处理器缓存行中的数据写回系统内存
- 这个写回操作会引起其他CPU里缓存的数据无效

为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器要对这个数据进行修改操作的时候，会强制重新从系统内存里把数据读到处理器缓存里。



队列集合类 LinkedTransferQueue，他在使用 Volatile 变量时，用一种追加字节的方式来优化队列出队和入队的性能。Doug lea 使用追加到 64 字节的方式来填满高速缓冲区的缓存行，避免头接点和尾节点加载到同一个缓存行，使得头尾节点在修改时不会互相锁定。

## SQL基础

distinct:SELECT DISTINCT country FROM Websites;

https://blog.csdn.net/qq_41936662/article/details/80393172

char和varchar的区别：

- 定长和变长：当插入的字符串超出他们的长度时，视情况而定，严格模式拒绝插入，宽松模式截取插入。char(10)表示存储10个字符，不够用空格填充。varchar插入多少是多少。varchar会记录字符串长度。

- 容量不同：char最多255个字符。varchar最多65532个字符

- 字符类型若为gbk，每个字符最多占2个字节，最大长度不能超过32766;

  字符类型若为utf8，每个字符最多占3个字节，最大长度不能超过21845。

聚集索引和非聚集索引

聚集索引,该索引中键值的逻辑顺序决定了表中相应行的物理顺序,聚集索引规定数据在表中的物理存储顺序.，因此一个表只能包含一个聚集索引。但该索引可以包含多个列（组合索引）聚集索引对于那些经常要搜索范围值的列特别有效。使用聚集索引找到包含第一个值的行后，便可以确保包含后续索引值的行在物理相邻



非聚集索引

一种索引，该索引中索引的逻辑顺序与磁盘上行的物理存储顺序不同。

mysam非聚集索引,有静态表(每个记录固定长度),动态表,压缩表(适合存储大字段)



填充因子:

创建索引时，可以指定一个填充因子，以便在索引的每个叶级页上留出额外的间隙和保留一定百分比的空间，供将来表的数据存储容量进行扩充和减少页拆分的可能性。填充因子的值是从  0  到  100  的百分比数值，指定在创建索引后对数据页的填充比例。值为  100  时表示页将填满，所留出的存储空间量最小。只有当不会对数据进行更改时（例如，在只读表中）才会使用此设置。值越小则数据页上的空闲空间越大，这样可以减少在索引增长过程中对数据页进行拆分的需要，但需要更多的存储空间。当表中数据会发生更改时，这种设置更为适当。

填充因子越大,意味着一个索引页包含的索引记录越多,空闲空间越小.一般来说查询的效率越高,因为这样查询的时候,可以减少读取索引页的工作量和减少内存使用  
 但这样导致的结果是数据变动导致的索引维护的工作量增加,因为索引页的空闲空间小,如果不能在本页内完成索引调整,就会引起调整其他索引页  
 **所以一般的选择是,数据基本不变化的（例如OLAP的场景，数据只用来分析的）,将填充因子设置到足够大,数据经常变化的（例如OLTP的场景）,将填充因子设置为足够小**



Mysql和MongoDB索引的物理结构

mysql使用b+树,而mongodb使用b树.

- b+树非叶子节点不保存数据,只有叶子节点保存数据
- B+树叶子节点使用指针前后相连
- B+树做遍历的时候会非常快,因为节点之间是相连的.而mysql是关系型数据库,遍历查询的操作比较多.例如两张表,学生表和班级表,查找一班的所有学生,这个时候需要查询出一班的id,然后根据id去遍历了学生表.而mongodb不需要遍历,因为学生和班级保存在一个文档中,学生用列表表示,只需要单一查询就可以查询到一班的所有学生.
- B树适合单一查询,首先它所有的节点上都有数据,也就是说不需要走到叶子节点就可以查询到需要的结果了,查询效率比较快.
- B树上有数据的话,那么在读入内存的时候,能够读入的记录条数会变少了.
- 为什么使用mongodb.从数据上来说,我保存的是Json格式的数据,有层级关系,也有列表等,从业务上来说,我需要的查询和保存操作比较频繁.都是单一查询,B树比较好.



Mysql的表锁和行锁

innodb基于索引的行锁,行锁是基于索引项来实现的,只有通过索引条件检索数据,才会使用行级锁.如果操作了主键索引,mysql会锁住这条主键索引.如果操作了非主键索引,会先锁定非主键索引,再锁定主键索引.mysql优化器发现,即使使用了索引,还是会进行全表扫描,就会使用表锁.



order by使用索引的情况

**ORDER BY子句，尽量使用Index方式排序**,避免使用FileSort方式排序
MySQL支持二种方式的排序，FileSort和Index，后者效率高，它指MySQL扫描索引本身完成排序。FileSort方式效率较低。ORDER BY满足以下情况，会使用Index方式排序:
      a)ORDER BY 语句使用索引最左前列。
      b)使用Where子句与Order BY子句条件列组合满足索引最左前列。
以下情况，会使用FileSort方式的查询

a)检查的行数过多，且没有使用覆盖索引。第3句，虽然跟第2句一样，order by使用了索引最左前列uid，但依然使用了filesort方式排序，因为status并不在索引中，所以没办法只扫描索引。
b)使用了不同的索引，MySQL每回只采用一个索引.第4句,order by出现二个索引，分别是uid_fuid和聚集索引(pk)
c)对索引列同时使用了ASC和DESC。 通过where语句将order by中索引列转为常量，则除外。第5句,和第6句在order by子句中，都出现了ASC和DESC排序,但是第5句却使用了filesort方式排序,是因为第6句where uid取出排序需要的数据,MySQL将其转为常量,它的ref列为const。
d)where语句与order by语句，使用了不同的索引。参见第7句。
e)where语句或者ORDER BY语句中索引列使用了表达式，包括函数表达式。参见第8，9句
f)where 语句与ORDER BY语句组合满足最左前缀，但where语句中使用了条件查询。查见第10句,虽然where与order by构成了索引最左有缀的条件，但是where子句中使用的是条件查询。
g)order by子句中加入了非索引列,且非索引列不在where子句中。
h)order by或者它与where组合没有满足索引最左前列。参见第11句和12句,where与order by组合，不满足索引最左前列. （uid, fsex)跳过了fuid
i)当使用left join，使用右边的表字段排序。参见第13句，尽管user.uid是pk，依然会使用filesort排序。

![img](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/26133439_dKZf.jpg)

![img](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/26133440_hDGB.jpg)

**慎用left join语句,避免创建临时表** 使用left join语句的时候，避免出现创建临时表。尽量不要用left join，分而治之。

**谨防where子句中的OR**。where语句使用or，且没有使用覆盖索引,会进行全表扫描。应该尽量避免这样OR语句。尽量使用UNION代替OR



Mysql中分库分表：

- 分成两个库，读写分离，如何确保读的操作是向从数据库中查询，写的时候是向主数据库中写？自定义@read和@write，注在Dao层的接口方法上。
- 

## Mybaits

使用的设计模式有哪些：

建造者模式：sqlSessionFactoryBuilder

日志模块使用设计模式：

- 1.mybaits没有实现日志的功能，需要引入第三方插件。使用适配器模式作为两个不兼容接口的桥梁。有目标接口，适配器，被适配的接口。
- 过LogFactory来实现自动扫描优先加载，自动扫描日志的实现，并把该实现的构造方法加载出来。
- 动态代理模式：解耦客户端和真实对象。防止直接访问的复杂性，对业务进行增强。日志模块对连接进行增强，例如打印sql语句。Proxy提供一个静态方法，负责生成动态代理类以及它的实例，静态方法为newProxyInstance，该方法返回指定接口的代理实例，该代理实例将方法调用调度到指定的调用处理程序。InvocationHandler是一个接口，每个代理实例都有一个关联的调用处理程序。在代理实例上调用方法时，该方法调用将被编码并分派到`invoke` 其调用处理程序的方法。invoke的功能是处理代理实例上的方法调用并返回结果。newProxyInstance中的三个参数，factory.getClass().getClassLoader()表示类加载器，factory.getClass().getInterfaces()表示实现的指定接口，this代表InvocationHandler。InvocationHandler只负责增强业务，Proxy只负责创建对象

数据源模块使用的设计模式：

- 工厂模式：符合开闭原则，将对象的创建和使用解耦。有多种数据源：unpooledDataSource,pooledDataSource分别有对应的工厂。也可以自定义数据源。
- 动态代理：用动态代理封装了数据库的连接对象，使用前检查连接是否有效，关闭时进行连接的回收。

缓存模块：

- 装饰器模式：是一种用于代替继承的技术，无需通过继承增加子类就能扩展对象的新功能，使用对象的关联关系代替继承关系。在运行期间可以动态的添加功能，可以对添加的功能进行自由组合。BlockingCache:阻塞版本的缓存装饰器，保证只有一个线程去数据库查找指定的key对应的数据（加锁ReentrantLock）。
- 一级缓存：是以sqlSession为生命周期的，生命周期比较短，当这个session关闭，缓存也就没有了，是线程独享的。sqlSession代表一次数据库连接，要保证线程独享。
- 二级缓存：是以sqlSessionFactory为生命周期，以命名空间为单位的，一个mapper文件共享一个缓存，所以会使得多个线程共享二级缓存，会出现脏读的情况。sqlSessionFactory是工厂单例模式，存在于整个生命周期。

mybatis核心流程三大阶段：

- 初始化阶段：读取XML配置文件和注解中的配置信息，创建配置对象，并完成各个模块的初始化的工作
- 代理阶段：使用mapper接口开发的初始化工作
- 数据读写阶段：通过sqlSession完成SQL解析，参数的映射，sql的执行，结果的解析过程。

MyBatis初始化：

- 建造者模式：使用多个简单的对象一步一步构建成一个复杂的对象。

  - builder接口：定义产品各个组成部分的构建
  - builder的实现类：实现了具体每个部分的创建，并生成产品实例。
  - 指导者：调用具体builder实现类，指导创建，按照某种顺序等

  遇到多个构造器参数时，可以考虑使用建造者

  一个对象的实例化是依赖各个组件的产生以及装配顺序，关注的是一步步组装出目标对象。

- XMLConfigBuilder:解析mybatis-config.xml

- XMLMapperBuilder:解析映射配置文件

- XMLStatementBuilder:解析映射配置文件中的SQL节点

Binding模块

- 为什么使用mapper接口就能操作数据库：配置文件解读和动态代理增强



Mybaits接口层：

- 策略模式：SqlSession是Mybaits对外提供的最关键的核心接口，通过它可以执行数据库的读写命令，获取映射器，管理事务等。SqlSession的策略模式体现在，在配置文件中，数据源有三种方式，每一种对应着创建数据源的方法。

核心组件Excutor：

- 模板模式
- 流程：SqlSession执行SQL>Executor.query>获取sql信息>拼装缓存的key>判断是否需要清空缓存>根据缓存Key查找一级缓存>是否命中一级缓存>查询数据库得到结果>保存结果到一级缓存>缓存延迟加载处理。
- Excutor接口，用来操作数据库
  - SimpleExecutor:使用PrepareStatement对象访问数据库，每次访问都会创建新的PrepareStatement
  - ReuseExcutor:使用预编译PrepareStatement对象访问数据库，会重用statement对象
  - BatchExector:实现批量执行多条SQL语句的能力

## 线程

创建线程的几种方式

- 继承Thread类
- 实现runable接口
- 实现callable接口

开启线程的几种方式：

- 异步委托： 创建线程的一种简单方式是定义一个委托,并异步调用它。 委托是方法的类型安全的引用。Delegate类 还支持异步地调用方法。在后台,Delegate类会创建一个执行任务的线程。
- Thread类
- 线程池
- 任务

```java
ExecutorService pool = Executors.newFixedThreadPool(3);
pool.execute(thread1)//thread必须是runable类型的，可以是实现runable接口的，也可以继承自Thread，因为Thread就是实现了Runable接口。将thread1放入线程池中执行。
Future<String> f = pool.submit(new TestThread());//提交任务，可以是callable类型，也可以是runable类型，只是runable类型会返回空。
```

所有BlockingQueue 都可用于传输和保持提交的任务。可以使用此队列与池大小进行交互：

如果运行的线程少于 corePoolSize，则 Executor始终首选添加新的线程，而不进行排队。（如果当前运行的线程小于corePoolSize，则任务根本不会存放，添加到queue中，而是直接抄家伙（thread）开始运行）

如果运行的线程等于或多于 corePoolSize，则 Executor始终首选将请求加入队列，**而不添加新的线程**。

如果无法将请求加入队列，则创建新的线程，除非创建此线程超出 maximumPoolSize，在这种情况下，任务将被拒绝。

**queue上的三种类型。**

 

排队有三种通用策略：

**直接提交。**工作队列的默认选项是 SynchronousQueue，它将任务直接提交给线程而不保持它们。在此，如果不存在可用于立即运行任务的线程，则试图把任务加入队列将失败，因此会构造一个新的线程。此策略可以避免在处理可能具有内部依赖性的请求集时出现锁。直接提交通常要求无界 maximumPoolSizes 以避免拒绝新提交的任务。当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性。

**无界队列。**使用无界队列（例如，不具有预定义容量的 LinkedBlockingQueue）将导致在所有corePoolSize 线程都忙时新任务在队列中等待。这样，创建的线程就不会超过 corePoolSize。（因此，maximumPoolSize的值也就无效了。）当每个任务完全独立于其他任务，即任务执行互不影响时，适合于使用无界队列；例如，在 Web页服务器中。这种排队可用于处理瞬态突发请求，当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性。

**有界队列。**当使用有限的 maximumPoolSizes时，有界队列（如 ArrayBlockingQueue）有助于防止资源耗尽，但是可能较难调整和控制。队列大小和最大池大小可能需要相互折衷：使用大型队列和小型池可以最大限度地降低 CPU 使用率、操作系统资源和上下文切换开销，但是可能导致人工降低吞吐量。如果任务频繁阻塞（例如，如果它们是 I/O边界），则系统可能为超过您许可的更多线程安排时间。使用小型队列通常要求较大的池大小，CPU使用率较高，但是可能遇到不可接受的调度开销，这样也会降低吞吐量。 

**BlockingQueue的选择。**

**例子一：使用直接提交策略，也即SynchronousQueue。**

首先SynchronousQueue是无界的，也就是说他存数任务的能力是没有限制的，但是由于该Queue本身的特性，**在某次添加元素后必须等待其他线程取走后才能继续添加**。在这里不是核心线程便是新创建的线程，？如果你的任务A1，A2有内部关联，A1需要先运行，那么先提交A1，再提交A2，当使用SynchronousQueue我们可以保证，A1必定先被执行，在A1么有被执行前，A2不可能添加入queue中。

**例子二：使用无界队列策略，即LinkedBlockingQueue**

这个就拿**newFixedThreadPool**来说，根据前文提到的规则：

如果运行的线程少于 corePoolSize，则 Executor 始终首选添加新的线程，而不进行排队。那么当任务继续增加，会发生什么呢？

如果运行的线程等于或多于 corePoolSize，则 Executor 始终首选将请求加入队列，而不添加新的线程。OK，此时任务变加入队列之中了，那什么时候才会添加新线程呢？

如果无法将请求加入队列，则创建新的线程，除非创建此线程超出 maximumPoolSize，在这种情况下，任务将被拒绝。这里就很有意思了，可能会出现无法加入队列吗？不像SynchronousQueue那样有其自身的特点，对于无界队列来说，总是可以加入的（资源耗尽，当然另当别论）。换句说，永远也不会触发产生新的线程！corePoolSize大小的线程数会一直运行，忙完当前的，就从队列中拿任务开始运行。所以要防止任务疯长，比如任务运行的实行比较长，而添加任务的速度远远超过处理任务的时间，而且还不断增加，不一会儿就爆了。

**例子三：有界队列，使用ArrayBlockingQueue。**

这个是最为复杂的使用，所以JDK不推荐使用也有些道理。与上面的相比，最大的特点便是可以防止资源耗尽的情况发生。对于首先来的A,B来说直接运行，接下来，如果来了C,D，他们会被放到queue中，如果接下来再来E,F，则增加线程运行E，F。但是如果再来任务，队列无法再接受了，线程数也到达最大的限制了，所以就会使用拒绝策略来处理。

**RejectedExecutionHandler**

另一种情况便是，即使向老板借了工人，但是任务还是继续过来，还是忙不过来，这时整个队伍只好拒绝接受了。

RejectedExecutionHandler接口提供了对于拒绝任务的处理的自定方法的机会。在ThreadPoolExecutor中已经默认包含了4中策略，因为源码非常简单，这里直接贴出来。

**CallerRunsPolicy**：线程调用运行该任务的 execute 本身。此策略提供简单的反馈控制机制，能够减缓新任务的提交速度。

这个策略显然不想放弃执行任务。但是由于池中已经没有任何资源了，那么就直接使用调用该execute的线程本身来执行。

**AbortPolicy：**处理程序遭到拒绝将抛出运行时RejectedExecutionException

 这种策略直接抛出异常，丢弃任务。

**DiscardPolicy：**不能执行的任务将被删除

 这种策略和AbortPolicy几乎一样，也是丢弃任务，只不过他不抛出异常。

**DiscardOldestPolicy：**如果执行程序尚未关闭，则位于工作队列头部的任务将被删除，然后重试执行程序（如果再次失败，则重复此过程）

该策略就稍微复杂一些，在pool没有关闭的前提下首先丢掉缓存在队列中的最早的任务，然后重新尝试运行该任务。这个策略需要适当小心。

设想:如果其他线程都还在运行，那么新来任务踢掉旧任务，缓存在queue中，再来一个任务又会踢掉queue中最老任务。

总结：

keepAliveTime和maximumPoolSize及BlockingQueue的类型均有关系。如果BlockingQueue是无界的，那么永远不会触发maximumPoolSize，自然keepAliveTime也就没有了意义。

反之，如果核心数较小，有界BlockingQueue数值又较小，同时keepAliveTime又设的很小，如果任务频繁，那么系统就会频繁的申请回收线程。





## Spring

IOC:控制反转：控制反转是一种思想，就是将设计好的对象交给容器控制，而不是传统的在对象内部直接控制。spring通过一个配置文件描述bean与bean之间的依赖关系，利用java的反射功能实例化bean并建立bean之间的依赖关系。将设计好的对象交给容器控制。

IOC容器：容器创建对象，将他们装配在一起，配置并管理他们的生命周期和对象之间的关系。IOC容器控制了对象，控制对象生命周期的不再是引用它的对象，而是spring容器。所有对象到spring容器中注册，在运行的时候，spring容器把该对象需要的资源给它，也会把它交给任何需要它的对象。IOC容器除了这些功能，还提供了bean实例缓存，生命周期管理，事件发布等

IOC启动先创建BeanFactory，它有一个getBean()方法用来获取bean.如果是IOC容器中没有，getBean的时候就会CreateBean,先初始化对象，然后属性赋值，然后initMethod方法，最后吧bean放到Map中。

spring会读取bean的配置信息，从xml文件或者configuartion类或者autowrite中，在spring容器中生成bean定义注册表，然后将注册表的对象全部实例化，并放到一个bean缓存池中，bean缓存池是hashmap结构的。

IOC好处：传统的程序是在类内部主动创建依赖的对象，会导致类之间的高度耦合。有了IOC容器可以把创建和查找依赖对象的控制权交给容器，由容器进行注入组合对象，所以对象与对象之间是松散耦合。

DI:依赖注入，由容器动态的将某个依赖关系注入到组件中。如何在运行期间将对象需要的资源给它呢，就是使用依赖注入

依赖注入的四种方式：

- 构造器注入
- set方法注入
- 静态工厂注入
- 实例工厂注入

手动装配：xml装配，构造方法，setter方法

装配：就是当Bean在spring容器中组合在一起的时候，怎么绑定在一起。

自动装配五种方式：

- no:默认不进行自动装配，通过ref属性进行装配
- byName:通过参数名进行装配@Autowire(name="")
- byType：通过参数类型进行自动装配
- constructor
- autodetect:先通过constructor，失败再用byType

@Autowired 可以更准确地控制应该在何处以及如何进行自动装配。此注解用于在 setter 方法，构造函数，具有任意名称或多个参数的属性或方法上自动装配bean。默认情况下，它是类型驱动的注。

当您创建多个相同类型的 bean 并希望仅使用属性装配其中一个 bean 时，您可
以使用@Qualifier 注解和 @Autowired 通过指定应该装配哪个确切的 bean
来消除歧义。

BeanFactory和FactoryBean:

- 两个都是接口

- BeanFactory是个Factory，也就是IOC容器或对象工厂,提供了IOC容器的基本形式，它面向spring本身，而ApplicationCintext面向使用者。所有的bean都是由beanFactory进行管理。用于实例化，定位，配置对象及对象之间的依赖关系。具体实现有XMlBeanFactory,ApplicationCintext。BeanFactory是提供了OC容器最基本的形式，给具体的IOC容器的实现提供了规范
- FactoryBean是一个bean，在IOC容器的基层上给bean的实现加上了一个简单工厂模式和装饰器模式。用户可以通过实现该接口定制实例化bean的逻辑，隐藏了实例化复杂bean的细节。



Spring bean的生命周期：

![Bean的生命周期](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/5-1ZF1100325116.png)

Bean 生命周期的整个执行过程描述如下。

1）根据配置情况调用 Bean 构造方法或工厂方法实例化 Bean。

2）利用依赖注入完成 Bean 中所有属性值的配置注入。

3）如果 Bean 实现了 BeanNameAware 接口，则 Spring 调用 Bean 的 setBeanName() 方法传入当前 Bean 的 id 值。

4）如果 Bean 实现了 BeanFactoryAware 接口，则 Spring 调用 setBeanFactory() 方法传入当前工厂实例的引用。

5）如果 Bean 实现了 ApplicationContextAware 接口，则 Spring 调用 setApplicationContext() 方法传入当前 ApplicationContext 实例的引用。

6）如果 BeanPostProcessor 和 Bean 关联，则 Spring 将调用该接口的预初始化方法 postProcessBeforeInitialzation() 对 Bean 进行加工操作，此处非常重要，Spring 的 AOP 就是利用它实现的。

7）如果 Bean 实现了 InitializingBean 接口，则 Spring 将调用 afterPropertiesSet() 方法。

8）如果在配置文件中通过 init-method 属性指定了初始化方法，则调用该初始化方法。

9）如果 BeanPostProcessor 和 Bean 关联，则 Spring 将调用该接口的初始化方法 postProcessAfterInitialization()。此时，Bean 已经可以被应用系统使用了。

10）如果在 <bean> 中指定了该 Bean 的作用范围为 scope="singleton"，则将该 Bean 放入 Spring IoC 的缓存池中，将触发 Spring 对该 Bean 的生命周期管理；如果在 <bean> 中指定了该 Bean 的作用范围为 scope="prototype"，则将该 Bean 交给调用者，调用者管理该 Bean 的生命周期，Spring 不再管理该 Bean。

11）如果 Bean 实现了 DisposableBean 接口，则 Spring 会调用 destory() 方法将 Spring 中的 Bean 销毁；如果在配置文件中通过 destory-method 属性指定了 Bean 的销毁方法，则 Spring 将调用该方法对 Bean 进行销毁。



AOP:

- 切面编程，切面就是与业务无关的，是业务模块共同调用的逻辑封装起来，减少重复代码，降低模块间的耦合度。
- AOP把系统分成两个部分，核心关注点和横切关注点，核心关注点是业务，横切关注点如权限认证，事务处理，日志等，指对哪些方法拦截，拦截后怎么处理
- 通知：拦截到连接点（被拦截到的方法）之后要执行的代码，通知分为前置，后置，异常，最终和环绕。
- JDK动态代理：InvocationHandler是一个接口，通过实现该接口定义横切逻辑，并通过反射机制调用目标类的代码，动态将横切逻辑和业务逻辑编制在一起。Proxy 利用 InvocationHandler 动态创建
  一个符合某一接口的实例，生成目标类的代理对象。
- CGLib动态代理：CGLib 全称为 Code Generation Library，是一个强大的高性能，高质量的代码生成类库，可以在运行期扩展 Java 类与实现 Java 接口，CGLib 封装了 asm，可以再运行期动态生成新
  的 class。和 JDK 动态代理相比较：JDK 创建代理有一个限制，就是只能为接口创建代理实例，
  而对于没有通过接口定义业务方法的类，则可以通过 CGLib 创建动态代理。

通知类型：

- 前置
- 后置
- 异常
- 最终
- 环绕

@Transaction注解

![image-20200721102850718](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200721102850718.png)

方法本地调用指使用this.调用

![image-20200721103147990](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200721103147990.png)

Spring解决循环依赖问题







## SpringMVC

拦截器：

- Spring MVC中的拦截器（Interceptor）类似于Servlet中的过滤器（Filter），它主要用于拦截用户请求并作相应的处理。例如通过拦截器可以进行权限验证、记录请求信息的日志、判断用户是否登录等。
  要使用Spring MVC中的拦截器，就需要对拦截器类进行定义和配置。通常拦截器类可以通过两种方式来定义。
  1.通过实现HandlerInterceptor接口，或继承HandlerInterceptor接口的实现类（如HandlerInterceptorAdapter）来定义。

  2.通过实现WebRequestInterceptor接口，或继承WebRequestInterceptor接口的实现类来定义。

SpringMVC启动过程：

- 配置阶段：配置web.xml，配置注解等
- 初始化阶段：
  - 调用init()方法加载配置文件
  - IOC容器初始化
  - 扫描相关类
  - IOC:创建bean并保存到容器
  - DI:给bean属性赋值
  - MVC:初始化HandlerMapping，将url和Method一一对应。
- 运行阶段：
  - 调用doPost,doGet，获得request和response对象
  - 匹配HandlerMapping,根据url找到对应的方法
  - 利用反射调用方法
  - 将结果返回输出给浏览器



SpringMVC 9大组件

​	1.HandlerMappings

​	2.HandlerAdapters：参数适配器

​	3.HandlerExceptionResolvers：异常拦截器

​	4.ViewResolvers：视图转换器

​	5.RequestToViewNameTranslator：视图预处理器

​	6.LocaleRresolver：本地语言环境

​	7.ThemeResolver：模板处理器

​	8.MultipartResolver：多文件上传组件

​	9.FlashMapManger：



SpringMVC工作流程：

1.用户发送请求至前端控制器 DispatcherServlet
2.DispatcherServlet 收到请求调用 HandlerMapping 处理器映射器。
3.处理器映射器根据请求 url 找到具体的处理器，生成处理器对象及处理器拦截器(如果有则
生成)一并返回给 DispatcherServlet。
4.DispatcherServlet 通过 HandlerAdapter 处理器适配器调用处理器
5.执行处理器(Controller，也叫后端控制器)。
6.Controller 执行完成返回 ModelAndView
7.HandlerAdapter 将 controller 执行结果 ModelAndView 返回给 DispatcherServlet
8.DispatcherServlet 将 ModelAndView 传给 ViewReslover 视图解析器
9.ViewReslover 解析后返回具体 View
10.DispatcherServlet 对 View 进行渲染视图（即将模型数据填充至视图中）。



第一步:用户发起请求到前端控制器（DispatcherServlet）

第二步：前端控制器请求处理器映射器（HandlerMappering）去查找处理器（Handle）：通过xml配置或者注解进行查找

第三步：找到以后处理器映射器（HandlerMappering）像前端控制器返回执行链（HandlerExecutionChain）

第四步：前端控制器（DispatcherServlet）调用处理器适配器（HandlerAdapter）去执行处理器（Handler）

第五步：处理器适配器去执行Handler

第六步：Handler执行完给处理器适配器返回ModelAndView

第七步：处理器适配器向前端控制器返回ModelAndView

第八步：前端控制器请求视图解析器（ViewResolver）去进行视图解析

第九步：视图解析器像前端控制器返回View

第十步：前端控制器对视图进行渲染

第十一步：前端控制器向用户响应结果



DispatcherServlet：作为前端控制器，整个流程控制的中心，控制其它组件执行，统一调度，降低组件之间的耦合性，提高每个组件的扩展性。

HandlerMapping：通过扩展处理器映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等。 

HandlAdapter：通过扩展处理器适配器，支持更多类型的处理器。

ViewResolver：通过扩展视图解析器，支持更多类型的视图解析，例如：jsp、freemarker、pdf、excel等。





## Redis

redis为什么是单线程的？

- 因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。

- redis是单线程的，省去了很多上下文切换线程的时间；也不存在多进程或者多线程导致的切换而消耗 CPU。但是如果CPU成为Redis瓶颈，或者不想让服务器其他CUP核闲置，那怎么办？

  可以考虑多起几个Redis进程，Redis是key-value数据库，不是关系数据库，数据之间没有约束。只要客户端分清哪些key放在哪个Redis进程上就可以了。

- redis使用多路复用技术，可以处理并发的连接。非阻塞IO 内部实现采用epoll，采用了epoll+自己实现的简单的事件框架。epoll中的读、写、关闭、连接都转化成了事件，然后利用epoll的多路复用特性，绝不在io上浪费一点时间。

- **不需要各种锁的性能消耗**

- 可以使用单线程多进程集群方案

redis为什么那么快

- 内存数据库，省去了IO的时间
- redis使用了单线程模型，IO多路复用，使用单线程来轮询描述符，将数据库的开关读写转换为事件，减少了线程的切换。
- redis使用单线程，也保证了每个操作的原子性
- redis使用hash结构，读取速度快。还有压缩表，跳表
- redis实现自己的事件分离器，效率比较高。

redis的序列化方式：

- JdkSerializationRedisSerializer，这是RedisTemplate类默认的序列化方式。若你没有自定义，那就是它了。首先它要求存储的对象都必须实现java.io.Serializable接口，比较笨重

  其次，他存储的为二进制数据，这对开发者是不友好的。使用JDK提供的序列化功能。 优点是反序列化时不需要提供（传入）类型信息(class)，但缺点是需要实现Serializable接口，还有序列化后的结果非常庞大，是JSON格式的5倍左右，这样就会消耗redis服务器的大量内存。

- StringRedisSerializer:也是StringRedisTemplate默认的序列化方式，key和value都会采用此方式进行序列化，是被推荐使用的，对开发者友好，轻量级，效率也比较高。

- Jackson2JsonRedisSerializer:从名字可以看出来，这是把一个对象以Json的形式存储，效率高且对调用者友好

  优点是速度快，序列化后的字符串短小精悍，不需要实现Serializable接口。

  但缺点也非常致命：那就是此类的构造函数中有一个类型参数，必须提供要序列化对象的类型信息(.class对象)。 通过查看源代码，发现其在反序列化过程中用到了类型信息（必须根据此类型信息完成反序列化）。

  这种的坏处，很显然，我们就不能全局使用统一的序列化方式了，而是每次调用RedisTemplate前，都需要类似这么处理：

  ```java
  redisTemplate.setKeySerializer(RedisSerializerType.StringSerializer.getRedisSerializer());
          redisTemplate.setValueSerializer(new Jackson2JsonRedisSerializer<>(Person.class));
  ```

- GenericJackson2JsonRedisSerializer：这种序列化方式不用自己手动指定对象的Class。所以其实我们就可以使用一个全局通用的序列化方式了。使用起来和JdkSerializationRedisSerializer基本一样。

  同样的JdkSerializationRedisSerializer不能序列化和反序列化不同包路径对象的毛病它也有。因为它序列化之后的内容，是存储了对象的class信息的：

- RedisTemplate在遇到复杂类型的返序列化时，即使加了泛型，获取到的实际类型为LinedHashMap，需要得到结果后再次反序列化，不然会报类型转换异常。

  如下：这样处理才是安全的：

  ![img](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/20190626163648992.png)

  在执行序列化的时候，操作的如果是Bean，必须有默认构造器，否则报错



Jedis是Redis官方推荐的面向Java的操作Redis的客户端，而RedisTemplate是SpringDataRedis中对JedisApi的高度封装。

SpringDataRedis相对于Jedis来说可以方便地更换Redis的Java客户端，比Jedis多了自动管理连接池的特性，方便与其他Spring框架进行搭配使用如：SpringCache。

为了多线程安全，以前是Jedis+JedisPool组合 ,现在在SpringBoot 2.0应用中直接使用`Lettuce客户端的API封装`RedisTemplate即可`，`只要配置好连接池属性，那么SpringBoot就能自动管理连接池。

Redis是一个应用程序,运行在操作系统上,端口是6379,java程序连接redis时候首先是和操作系统的内核建立起TCP连接,三次握手的代码就在内核中,当有涉及到redis的操作的时候,将命令放到redis的队列中,然后单个线程先读取一条命令,然后执行它,然后再写会IO,当执行完该命令时,才能读取下一条命令.

在redis6.0版本以后,redis实现了多线程,还是在队列中,线程分为一个计算的核心线程,和多个IO线程,当有命令来时,每来一条命令,就启动一个IO线程,进行命令的读取,读取完之后,交给核心线程去执行,执行完之后再交个IO线程写回.

## 分布式事务

理论：CAP理论和BASE理论

CAP:一致性，可用性，分区容错性(网络出现分区,例如分了两个区域,也要保持可用性)

BASE:基本可用，软状态，最终一致性,(根据CA权衡提出的)

BASE和ACID代表两种截然相反的设计理念，ACID注重一致性，是传统关系型数据库（MySQL）的设计思路，BASE关注高可用性。

分布式一致性算法：

- 2pc:基于XA协议的两阶段提交，XA中大致分为两部分：事务管理器和本地资源管理器。事务管理器负责本地资源的提交和回滚，本地资源管理器就是各种数据库。

  准备阶段：事务管理器发送请求到本地资源管理器，本地资源管理器会分别执行自己的事务，写日志到redo和undo中，但是不提交事务

  提交阶段：当事务管理器接收到资源管理器的成功通知，再发送commit命令提交，如果有一个资源准备阶段不成功，则回滚所有事务。

  优点：简单，实现方便

  缺点：同步阻塞，单点故障，数据不一致，容错机制不完善

- 3pc：三阶段提交

  canCommit阶段：确定所有资源都存在且可用，这里可以减少2阶段提交的阻塞时间。

  preCommit阶段：执行事务，写redo和undo

  doCommit阶段：提交事务，在超时后会默认执行commit操作，

  优点：改善同步阻塞，改善单点故障

  缺点：同步阻塞，单点故障，数据不一致，容错机制不完善

- paxos

- zab

- 事务补偿TCC模式

  TCC(Try-Confirm-Cancel)分布式事务模型相对于 XA 等传统模型，其特征在于它不依赖资源管理器(RM)对分布式事务的支持，而是通过对业务逻辑的分解来实现分布式事务。

  初步操作 Try：完成所有业务检查，预留必须的业务资源。

  确认操作 Confirm：真正执行的业务逻辑，不作任何业务检查，只使用 Try 阶段预留的业务资源。因此，只要 Try 操作成功，Confirm 必须能成功。另外，Confirm 操作需满足幂等性，保证一笔分布式事务有且只能成功一次。

  取消操作 Cancel：释放 Try 阶段预留的业务资源。同样的，Cancel 操作也需要满足幂等性。

  ![阿里P8架构师谈：分布式事务的解决方案，以及原理、总结](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/1537323603052d214acaf6b.jpeg)

  **TCC 分布式事务模型包括三部分**：

  **1.主业务服务**：主业务服务为整个业务活动的发起方，服务的编排者，负责发起并完成整个业务活动。

  **2.从业务服务**：从业务服务是整个业务活动的参与方，负责提供 TCC 业务操作，实现初步操作(Try)、确认操作(Confirm)、取消操作(Cancel)三个接口，供主业务服务调用。

  **3.业务活动管理器**：业务活动管理器管理控制整个业务活动，包括记录维护 TCC 全局事务的事务状态和每个从业务服务的子事务状态，并在业务活动提交时调用所有从业务服务的 Confirm 操作，在业务活动取消时调用所有从业务服务的 Cancel 操作。

  **一个完整的 TCC 分布式事务流程如下：**

  1.  主业务服务首先开启本地事务;
  2.  主业务服务向业务活动管理器申请启动分布式事务主业务活动;
  3.  然后针对要调用的从业务服务，主业务活动先向业务活动管理器注册从业务活动，然后调用从业务服务的 Try 接口;
  4.  当所有从业务服务的 Try 接口调用成功，主业务服务提交本地事务;若调用失败，主业务服务回滚本地事务;
  5.  若主业务服务提交本地事务，则 TCC 模型分别调用所有从业务服务的 Confirm 接口;若主业务服务回滚本地事务，则分别调用 Cancel 接口;
  6.  所有从业务服务的 Confirm 或 Cancel 操作完成后，全局事务结束。

  **TCC模型小结**

  所谓的TCC编程模式，也是两阶段提交的一个变种。TCC提供了一个编程框架，将整个业务逻辑分为三块：**Try、Confirm和Cancel**三个操作。以在线下单为例，Try阶段会去扣库存，Confirm阶段则是去更新订单状态，如果更新订单失败，则进入Cancel阶段，会去恢复库存。总之，TCC就是通过代码人为实现了两阶段提交，不同的业务场景所写的代码都不一样，复杂度也不一样，因此，这种模式并不能很好地被复用。

- 消息队列最终一致性方案：基于消息中间件的两阶段提交

  将一个分布式事务拆成一个消息事务（A系统的本地操作+发消息）+B系统的本地操作，其中B系统的操作由消息驱动，只要消息事务成功，那么A操作一定成功，消息也一定发出来了，这时候B会收到消息去执行本地操作，如果本地操作失败，消息会重投，直到B操作成功，这样就变相地实现了A与B的分布式事务。

  1、A系统向消息中间件发送一条预备消息

  2、消息中间件保存预备消息并返回成功

  3、A执行本地事务

  4、A发送提交消息给消息中间件

  -  步骤一出错，则整个事务失败，不会执行A的本地操作
  -  步骤二出错，则整个事务失败，不会执行A的本地操作
  -  步骤三出错，这时候需要回滚预备消息，怎么回滚？答案是A系统实现一个消息中间件的回调接口，消息中间件会去不断执行回调接口，检查A事务执行是否执行成功，如果失败则回滚预备消息
  -  步骤四出错，这时候A的本地事务是成功的，那么消息中间件要回滚A吗？答案是不需要，其实通过回调接口，消息中间件能够检查到A执行成功了，这时候其实不需要A发提交消息了，消息中间件可以自己对消息进行提交，从而完成整个消息事务

Raft:分布式共识

一个客户端和多个服务节点如何达成共识?

节点的三种状态:

- 跟随者
- 候选状态
- 领导者

工作原理:

- 所有节点都是从跟随者状态开始的,

- 如果跟随者在一定的时间内没有接受到领导者的心跳检测的消息,它就会成为候选人

- 候选人向其他节点请求投票

- 节点投票表决,如果它能收到一半以上的票,就会成为领导者,这个过程是选举

- 系统的所有更改都是通过领导者节点

- ## 每次更改都将添加为节点日志中的条目。该日志条目当前未提交，因此不会更新节点的值。要提交条目，节点首先将其复制到跟随者节点...然后领导者等待，直到大多数节点都写了该条目。现在，该条目已提交到引导者节点上，并且节点状态为“ 5”。领导者然后通知关注者该条目已提交。现在，集群已就系统状态达成共识。此过程称为*日志复制*。

- ## 在Raft中，有两个超时设置可控制选举。首先是选举超时。选举超时是指追随者成为候选人之前的等待时间。选举超时被随机分配在150毫秒至300毫秒之间。选举超时后，关注者成为候选人并开始新的*选举任期* ...

- ## ...并将*请求投票*消息发送给其他节点。如果接收节点在这个学期还没有投票，那么它将投票给候选人。...并且节点重置其选举超时。一旦候选人获得多数票，它就会成为领导者。领导者开始向其关注者发送“ *添加条目”*消息。这些消息以心跳超时指定的时间间隔发送。跟随者然后响应每个*追加条目*消息。此选举任期将持续到追随者停止接收心跳并成为候选人为止。

- ## 让我们停止领导，观察选举连任。要获得多数票，可以保证每学期只能选出一位领导人。如果两个节点同时成为候选节点，则可能会发生拆分表决

- ## 两个节点都开始以相同的任期进行选举...![image-20200726235343165](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200726235343165.png)

- ## 现在，每位候选人都有2票，并且在这个任期中将无法获得更多选票。节点B在第5届中获得了多数选票，因此成为领导者。

- ## 当选出一位领导者后，我们需要将系统的所有更改复制到所有节点。通过使用与心跳相同的“ *添加条目”*消息来完成此操作。首先，客户将更改发送给领导者。更改将添加到领导者的日志中......然后将更改在下一个心跳发送给关注者。一旦大多数追随者认可，便提交该条目。...并且响应被发送到客户端。

- ## 面对网络分区，raft甚至可以保持一致。由于我们的分区，我们现在有两位领导人,他们的term不同。

- 修复网络分区,节点B将看到较高的选举期限并退出,节点A和B都将回滚其未提交的条目并匹配新领导者的日志。



## Linux

JVM内存溢出问题排查命令

- jcmd： jcmd -l 列出正在执行的java进程id
- jmap： jmap -heap PID打印堆信息，jmap -histo[:live]打印对象列表

查看服务器的并发连接数：

- ```
  netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'
  ```

  ```java
  解释:
  
  返回结果示例： 
  LAST_ACK 5   (正在等待处理的请求数) 
  SYN_RECV 30 
  ESTABLISHED 1597 (正常数据传输状态) 
  FIN_WAIT1 51 
  FIN_WAIT2 504 
  TIME_WAIT 1057 (处理完毕，等待超时结束的请求数) 
   
  状态：描述 
  CLOSED：无连接是活动的或正在进行 
  LISTEN：服务器在等待进入呼叫 
  SYN_RECV：一个连接请求已经到达，等待确认 
  SYN_SENT：应用已经开始，打开一个连接 
  ESTABLISHED：正常数据传输状态 
  FIN_WAIT1：应用说它已经完成 
  FIN_WAIT2：另一边已同意释放 
  ITMED_WAIT：等待所有分组死掉 
  CLOSING：两边同时尝试关闭 
  TIME_WAIT：另一边已初始化一个释放 
  LAST_ACK：等待所有分组死掉
  ```

  使用这上面的命令是可以查看服务器的种连接状态，其中ESTABLISHED 就是并发连接状态的显示数的了。如果你不想查看到这么多连接状态，而仅仅只是想查看并发连接数，可以简化一下命令，即：

  ```java
  netstat -nat|grep ESTABLISHED|wc -l
  1164
  ```




## Nginx

客户端的反向代理层高可用，通过反向代理的冗余来实现，一台nginx提供服务，另一台做冗余，使用keepalived存活探测，然后故障自动转移，使用相同的虚拟IP,切换的过程对用方透明。

站点层高可用，通过站点层的冗余来实现，配置多个web后端

在上述的准备工作介绍到了本次配置高可用将采用`Keepalived`来实现，那么什么是`Keepalived`?

`Keepalived`是一款`服务器状态检测和故障切换的工具`，起初是专为`LVS负载均衡`软件设计的，用来`管理`并`监控LVS集群`系统中`各个服务节点的状态`，后来又加入了可以实现高可用的VRRP (Virtual Router Redundancy Protocol ,虚拟路由器冗余协议）功能。

因此，`Keepalived`除了能够管理`LVS`软件外，还可以作为其他服务（`例如：Nginx、Haproxy、MySQL等`）的高可用解决方案软件在其配置文件中，可以配置主备服务器和该服务器的状态检测请求。也就是说`keepalived`可以根据配置的请求，在提供服务期间不断向指定服务器发送请求，如果该请求返回的状态码是200，则表示该服务器状态是正常的，如果不正常，那么`Keepalived`就会将该服务器给下线掉，然后将备用服务器设置为上线状态，而当主服务器节点恢复时，备服务器节点会释放主节点故障时自身接管的 IP 资源及服务，恢复到原来的备用角色。

高可用

> 整个互联网分层系统架构的高可用，是通过每一层的`冗余+自动故障转移`来实现的，具体的：
>
> - **【客户端层】到【反向代理层】的高可用**：是通过反向代理层的冗余实现的，常见实践是`keepalived + virtual IP`自动故障转移；
> - **【反向代理层】到【站点层】的高可用**：是通过站点层的冗余实现的，常见实践是`nginx`与`web-server`之间的存活性探测与自动故障转移；
> - **【站点层】到【服务层】的高可用**：是通过服务层的冗余实现的，常见实践是通过`service-connection-pool`来保证自动故障转移；
> - **【服务层】到【缓存层】的高可用**：是通过缓存数据的冗余实现的，常见实践是`缓存客户端双读双写`，或者利用`缓存集群的主从数据同步`与`sentinel`与`自动故障转移`；更多业务场景，对缓存没有高可用要求，可使用缓存服务化来对调用方屏蔽底层复杂性；
> - **【服务层】到【数据库“读”】的高可用**：是通过读库的冗余实现的，常见实践是通过`db-connection-pool`来保证自动故障转移；
> - **【服务层】到【数据库“写”】的高可用**：是通过写库的冗余实现的，常见实践是`keepalived + virtual IP`自动故障转移；

一个tomcat的最大并发是500个连接,所以需要负载均衡连接多个tomcat

负载均衡操作是什么?

负载均衡策略:

- 轮询
- 权重轮询
- 随机
- 权重随机
- 响应速度均衡:负载均衡设备对内部各个服务器发出探测请求,如(ping)
- 最少连接数均衡
- 处理能力均衡
- DNS响应均衡
- 一致性hash算法:相同参数的请求总数发到同一个提供者,当提供者挂了,基于虚拟节点
- IP地址散列
- URL散列



LVS高可用
通过KeepAlive实现,keepalive中添加了虚拟路由冗余协议后,可以为nginx提供服务,解决静态路由的单点故障问题.

LVS是对请求数据包的转发和传递,对应真实的服务器来说,接受到的请求还是来自客户端真实的用户.

反向代理是代理用户,从新对节点下的服务器发送请求,最后把数据返回给客户端.

HTTPS加密:RSA





## SpringBoot

热部署：引入devtools依赖，devtools原理是使用了两个ClassLoader，一个classLoader加载那些不会改变的类（第三方的jar包）另一个ClassLoader加载会更改的类，称为restart ClassLoader，这样在代码更改的时候，原来的restart classLoader被丢弃，重新创建一个restart ClassLoader。

使用javaConfig配置bean的方式，而不再使用xml，可以获得类型安全检查的好处，用法非常简单：

1.用@Configuration注解JavaConfig类，

2.用每个方法来表示Bean并使用@Bean注解方法。

3.每个方法名代表XML配置文件中的name





## RabbitMQ

#### 怎么保证消息不会重复消费？

原因：

- 生成者发送消息给mq,mq收到之后在返回confirm之前网络出现问题，导致消费者发送两次
- mq与消费者传输消息后，在消费者确认之前出现网络问题，导致mq向其他的消费者发送消息

对每条消息，**MQ系统内部必须生成一个inner-msg-id**，作为去重和幂等的依据，这个内部消息ID的特性是：

（1）全局唯一

（2）MQ生成，具备业务无关性，对消息发送方和消息接收方屏蔽

这个可以解决第一个问题



为了保证业务幂等性，业务消息体中，必须有一个biz-id，作为去重和幂等的依据，这个业务ID的特性是：

（1）对于同一个业务场景，全局唯一

（2）由业务消息发送方生成，业务相关，对MQ透明

（3）由业务消息消费方负责判重，以保证幂等

最常见的业务ID有：支付ID，订单ID，帖子ID等。

第 1 条很好理解，只要保持幂等性，不管来多少条重复消息，最后处理的结果都一样。第 2 条原理就是利用一张日志表来记录已经处理成功的消息的 ID，如果新到的消息 ID 已经在日志表中，那么就不再处理这条消息。可以将id放在缓存中或者数据库中

**RabbitMQ 不保证消息不重复，如果你的业务需要保证严格的不重复消息，需要你自己在业务端去重。**

这个解决了第二个问题



#### 怎么保证消息不丢失？

1.生产者和消费者为了避免弄丢消息，都是采用了确认模式，确认模式是异步的，等待确认的同时不影响其他消息的发送。还有一种方法是开启事务，但是这是一个同步的操作，通常不会使用。

```
首先生产者通过调用channel.confirmSelect方法将信道设置为confirm模式，一旦信道进入confirm模式，所有在该信道上面发布的消息都会被指派一个唯一的ID（从1开始），一旦消息被投递到所有匹配的队列之后，RabbitMQ就会发送一个确认（Basic.Ack）给生产者（包含消息的唯一deliveryTag和multiple参数），这就使得生产者知晓消息已经正确到达了目的地了。

其实Confirm模式有三种方式实现：

串行confirm模式：producer每发送一条消息后，调用waitForConfirms()方法，等待broker端confirm，如果服务器端返回false或者在超时时间内未返回，客户端进行消息重传。
批量confirm模式：producer每发送一批消息后，调用waitForConfirms()方法，等待broker端confirm。
异步confirm模式：提供一个回调方法，broker confirm了一条或者多条消息后producer端会回调这个方法。 我们分别来看看这三种confirm模式
异步模式需要自己多写一部分复杂的代码实现，异步监听类，监听server端的通知消息，异步的好处性能会大幅度提升，发送完毕之后，可以继续发送其他消息。 MQServer通知生产端ConfirmListener监听类：用户可以继承接口实现自己的实现类，处理消息确认机制
```

- 发送消息之前需要把消息存起来
- 监听ack和nack并做出响应处理

```
我们分析下，可以使用SortedMap 存储，保证有序，但是有个问题高并发情况下， 每秒可能几千甚至上万的消息投递出去，消息的ack要等几百毫秒的话，放内存可能有内存溢出的风险。所以建议采用KV存储，KV存储承载高并发能力高，性能好，但是要保证KV 高可用，单个有个缺点就是又引入了第三方中间件，复杂度升高。
```

如果生产者发送到MQ的交换器上，但是这个交换器没有匹配的队列怎么办，消息还是会丢失。

- 使用mandatory设置为true

- 利用备份交换器，存储没有被路由到队列的消息

  当你新建一个exchange业务的时候，可以给它设置Arguments，这个参数就是 alternate-exchange，其实alternate-exchange就是一个普通的exchange，类型最好是fanout 方便管理

```java
 void basicPublish(String exchange, String routingKey, boolean mandatory, boolean immediate, BasicProperties props, byte[] body)
            throws IOException;
            
当mandatory标志位设置为true时，如果exchange根据自身类型和消息routeKey无法找到一个符合条件的queue， 那么会调用basic.return方法将消息返回给生产者
    当mandatory设置为false时，出现上述情形broker会直接将消息扔掉。
  /**
     * 当immediate标志位设置为true时，如果exchange在将消息路由到queue(s)时发现对于的queue上没有消费者， 那么这条消息不会放入队列中。
     当immediate标志位设置为false时,exchange路由的队列没有消费者时，该消息会通过basic.return方法返还给生产者。
     * RabbitMQ 3.0版本开始去掉了对于immediate参数的支持，对此RabbitMQ官方解释是：这个关键字违背了生产者和消费者之间解耦的特性，因为生产者不关心消息是否被消费者消费掉
     */
  
```





2.MQ为了避免消息丢失，使用的是持久化

- mq持久化时候，要把消息，路由，队列全部持久化
- 单节点问题
- 集群模式：因为RabbitMQ 集群模式有点特殊，队列的内容仅仅存在某一个节点上面，不会存在所有节点上面，所有节点仅仅存放消息结构和元数据（可以理解为索引，这也是为了提高性能，如果每次把所有内容同步到所有节点是有开销代价的）。

镜像模式至少采用3节点，2个磁盘节点和1个内存节点来保证，架构图：

![img](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/16cddf2040909d51)

1.消息支持持久化到Commitlog里面，即使宕机后重启，未消费的消息也是可以加载出来的

2.Broker自身支持同步刷盘、异步刷盘的策略，可以保证接收到的消息一定存储在本地的内存中

3.Broker集群支持 1主N从的策略，支持同步复制和异步复制的方式，同步复制可以保证即使Master 磁盘崩溃，消息仍然不会丢失





3.消费者挂掉导致消息丢失了怎么办？

如果消费端接受到消息之后还没有消费，就挂掉了，因为自动确认机制，mq中已经将消息删除了，这个时候消息就丢失了，怎么办？

- 采用手动ack机制，消费端处理完之后再通知mq，如果没处理完就挂了，mq会自动感知到连接断开了，会自动重发消息给其他的消费者。



#### 如何保证消息的顺序性

场景：比如下单操作，下单成功之后，会发布创建订单和扣减库存消息，但扣减库存消息执行会先于创建订单消息，也就说前者执行成功之后，才能执行后者。

不保证完全按照顺序消费，在 MQ 层面支持消息的顺序处理开销太大，为了极少量的需求，增加整体上的复杂度得不偿失。

所以，**还是在应用层面处理比较好，或者业务逻辑进行处理**。

应用层解决方式：

- **1.** 消息实体中增加：版本号 & 状态机 & msgid & parent_msgid，通过 parent_msgid 判断消息的顺序（需要全局存储，记录消息的执行状态）。
- **2.** “同步执行”：当一个消息执行完之后，再发布下一个消息。
- 队列只绑定一个消费者，所以最终的消费保证了顺序性。

#### 为什么使用mq

1.服务解耦：生产者和消费者解耦

2.异步通信

3.流量削峰

4.定时任务



#### MQ缺点

1.系统可用性降低，mq挂了所有服务就挂了

2.系统复杂性提高：要保证不会重复消费，处理消息丢失，保证消息传递的顺序性

3.一致性问题

a、确保生产者一定要将数据投递到MQ服务器中(采用MQ消息确认机制)
b、确保消费者能够正确消费消息，采用手动ACK模式(注意重试、幂等性问题)
c、如何保证第一个事务先执行，采用补偿机制，在创建一个补单消费者进行监听，如果订单没有创建成功，进行补单。(如果第一个事务中出错，补单消费者会在重新执行一次第一个事务，例如第一个事务是添加订单表，如果失败在补单的时候重新生成订单记录，由于订单号唯一，所以不会重复)





**1、保证消息不丢失(三步)**
1.1、开启事务(不推荐)
1.2、开启confirm(推荐)
1.3、开启RabbitMQ持久化(交换机、队列、消息)
1.4、关闭RabbitMQ自动ack(改成手动)

**2、保证消息不重复消费**
2.1、幂等性(每个消息用一个唯一标识来区分，消费前先判断标识有没有被消费过，若已消费过，则直接ACK)

**3、RabbitMQ如何保证消息的顺序性**
将消息放入同一个交换机，交给同一个队列，这个队列只有一个消费者，消费者只允许同时开启一个线程

**4、RabbitMQ消息重试机制**
消费者在消费消息的时候，如果消费者业务逻辑出现程序异常，这时候应该如何处理？
答案：使用消息重试机制(SpringBoot默认3次消息重试机制)

如何合适选择重试机制
消费者取到消息后，调用第三方接口，接口无法访问，需要使用重试机制
消费者取到消息后，抛出数据转换异常，不需要重试机制，需要发布者进行解决。

**5、SpringBoot消息重试机制**
@EnableRetry注解：表示启用重试机制(value表示哪些异常需要触发重试，maxAttempts设置最大重试次数，delay表示重试的延迟时间，multiplier表示上一次延时时间是这一次的倍数)
eg、@Retryable(value = Exception.class, maxAttempts = 3, backoff = @Backoff(delay = 2000, multiplier = 1.5))

@Recover注解：当重试次数达到设置的最大次数的时候，程序还是执行异常，调用的回调函数。

**6、RabbitMQ死信队列**
死信队列是当消息在一个队列因为下列原因:
a、消息被拒绝(basic.reject或basic.nack)并且requeue=false.
b、消息TTL过期
c、队列达到最大长度(队列满了，数据无法添加到mq中)
变成了 “死信队列” 后被重新投递(publish)到另一个Exchange，然后重新消费。说白了就是没有被消费的消息换个地方重新被消费

**7、RabbitMQ解决分布式事务**

经典案例，以目前流行的外卖为例，用户下单后，调用订单服务，订单服务调用派单系统通知送外卖人员送单，这时候订单系统与派单系统采用MQ异步通讯。

RabbitMQ解决分布式事务原理
答案：采用最终一致性原理

需要保证以下三要素:
a、确保生产者一定要将数据投递到MQ服务器中(采用MQ消息确认机制)
b、确保消费者能够正确消费消息，采用手动ACK模式(注意重试、幂等性问题)
c、如何保证第一个事务先执行，采用补偿机制，在创建一个补单消费者进行监听，如果订单没有创建成功，进行补单。(如果第一个事务中出错，补单消费者会在重新执行一次第一个事务，例如第一个事务是添加订单表，如果失败在补单的时候重新生成订单记录，由于订单号唯一，所以不会重复)

**8、RabbitMQ保证消息不丢失的具体方案**
前提：
(1)开启confirm
(2)开启RabbitMQ的持久化(交换机、队列、消息)
(3)关闭RabbitMQ的自动ack(改成手动)
(4)配置消费重试次数，消费重试间隔时间等

涉及到的技术点：
MQ、Redis、定时任务

8.1、保证投放消息不丢失
(1)先将消息放入生产者Redis(此时消息的状态为未投放)，再放入队列
(2)根据confirm(ReturnCallback和ConfirmCallback)的结果来确定消息是否投递成功，
投递成功的，修改生产者redis中消息的投递状态为已投递
投递失败的消息将会放入失败的Redis，并从生产者Redis中删除，由定时任务定期扫描并重新投递

(3)生产者Redis定时任务
生产者Redis定时任务专门扫描生产者Redis中存放了一定时间，但是状态还是未投放的消息
此消息会被认为已经投递，但是没有任何反馈结果(由于不可知因素，导致没有ReturnCallback，也没有ConfirmCallback)，
此类消息被扫描到后，会放入失败的Redis，并从生产者Redis中删除，由定时任务定期扫描并重新投递
(4)还需要一个专门的定时任务扫描生产者Redis中存放了很久，仍然未消费的数据(状态为已投递)，此类消息被扫描到后，会放入失败的Redis，并从生产者Redis中删除，由定时任务定期扫描并重新投递
(5)扫描失败的Redis的定时任务都遵循一条原则，一条消息最多被重新投递三次，若投递了三次仍然失败，则记录日志，记录到数据库，不会再投递，需要人工干预处理

8.2、保证消费消息不丢失
(1)消费者取到消息后，从消息中取出唯一标识，先判断此消息有没有被消费过，若已消费过，则直接ACK(避免重复消费)
(2)正常处理成功后，将生产者Redis中的此消息删除，并ACK(告诉server端此消息已成功消费)
(3)遇到异常时，捕获异常，验证自己在消息中设定的重试次数是否超过阀值，若超过，则放入死信队列，若未超过，则向将消息中的重试次数加1，抛出自定义异常，进入重试机制
(4)有专门的消费者用于处理死信队列中消费多次仍未消费成功的数据，可以记录日志，入库，人工干预处理





## 分布式



![image-20200721111923244](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200721111923244.png)

![image-20200721112352488](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200721112352488.png)

![image-20200721124356019](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200721124356019.png)

单个tomcat能够承受多少tps   500

数据量：mysql单表是700万

![image-20200721125845890](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200721125845890.png)

## 网络

ARP:

![image-20200725100513842](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200725100513842.png)

![image-20200725100733843](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200725100733843.png)

![image-20200725100943058](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200725100943058.png)

![image-20200725101216909](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200725101216909.png)



32位无符号整数 ， 其表示范围是2的32次方，最大整数为 2的32次方-1
有符号数则要去除一个符号位，正数最大为2的31次方-1 , 负数最小为负 2的31次方 

![image-20200707093900439](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200707093900439.png)



ip地址分类

![img](https://images2015.cnblogs.com/blog/603942/201610/603942-20161024110345781-1165410356.png)

![image-20200707182147854](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200707182147854.png)

IP地址就是给英特网上的每个主机（路由器）的每个接口分配一个在全世界范围内是唯一的32位的标识符。其组成第一个字段是网络号，第二个字段是主机号。一个主机号在前面的网络号所指明的网络范围内必须是唯一的，所以一个IP地址在整个网络中都是唯一的。目前分为A、B、C、D、E 五类IP地址。

![img](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/20170604163951489.png)

在A、B、C 三类地址中灰色的部分即为网络号，网络号的前三位是类别位，分别是0,10，110。也就是说我们可以凭借这个类别位置来判断网络类别。
32位的总长度，由于A、B、C 三类网络号的长度的不同，导致A、B、C 类地址的主机号字段的字节数分别为3、2、1（一个字节8位）。
D 类地址的网络号为1110，用于多播（一对多通讯）。E 类地址的网络号为1111，保留以后使用。



IP获取

### 动态主机设置协定（Dynamic Host Configuration Protocol, DHCP）

能自动bai获取IP是应为有一个DHCP服务器存在，du有可能是路由器，也有可能是专zhi门架设dao的DHCP服务器。
假设第一次分配到的IP是192.168.1.10，租约是六小时，那么到三小时后你的主机会向DHCP服务器请求续约，得到回应后租约再次延续为六小时，期间这个IP不会被别的计算机获得，就算别人强行设置也得不到该IP，除非是DHCP服务器手动设置或者进行绑定。
同时计算机内会有IP地址缓存，如果缓存还在的话下次开机得到的IP地址还是原先的IP地址，不过如果该地址已经被其他计算机获得，那就得不到该IP了。

- ### 发现阶段：DHCP客户机寻找DHCP服务器的阶段

 

当DHCP客户机第一次登录网络的时候（也就是客户机上没有任何IP地址数据时），它会通过UDP 67端口向网络上发出一个DHCPDISCOVER数据包（包中包含客户机的MAC地址和计算机名等信息）。因为客户机还不知道自己属于哪一个网络，所以封包的源地址为0.0.0.0，目标地址为255.255.255.255，然后再附上DHCP discover的信息，向网络进行广播，网络上每一台安装了[TCP/IP协议](http://www.baike.com/wiki/TCP/IP协议)的主机都会接收到这种广播信息，但只有DHCP服务器才会做出响应。

- ### **提供****IP****地址租用**：DHCP服务器提供IP地址的阶段

在网络中接收到DHCPdiscover发现信息的DHCP服务器都会做出响应，它从尚未出租的IP地址中挑选一个分配给DHCP客户机，DHCP为客户保留一个IP地址，然后通过网络广播一个DHCPOFFER消息给客户。该消息包含客户的MAC地址、服务器提供的IP地址、子网掩码、租期以及提供IP的DHCP服务器的IP。此时还是使用广播进行通讯，源IP地址为DHCP Server的IP地址，目标地址为255.255.255.255。同时，DHCP Server为此客户保留它提供的IP地址，从而不会为其他DHCP客户分配此IP地址。

 

- ### 选择阶段：即DHCP客户机选择某台DHCP服务器提供的IP地址的阶段

如果客户机收到网络上多台DHCP服务器的响应，只会挑选其中一个DHCP OFFER（一般是最先到达的那个），并且会向网络发送一个DHCP REQUEST广播数据包（包中包含客户端的MAC地址、接受的租约中的IP地址、提供此租约的DHCP服务器地址等），告诉所有DHCP Server它将接受哪一台服务器提供的IP地址，所有其他的DHCP服务器撤销它们的提供以便将IP地址提供给下一次IP租用请求。此时，由于还没有得到DHCP Server的最后确认，客户端仍然使用0.0.0.0为源IP地址，255.255.255.255为目标地址进行广播。

- ### **租约**确认阶段：即DHCP服务器确认所提供的IP地址的阶段

当DHCP Server接收到客户机的DHCP REQUEST之后，会广播返回给客户机一个DHCP ACK消息包，表明已经接受客户机的选择，并将这一IP地址的合法租用以及其他的配置信息都放入该广播包发给客户机。

客户机在接收到DHCP ACK广播后，会向网络发送三个针对此IP地址的ARP解析请求以执行冲突检测，查询网络上有没有其它机器使用该IP地址；如果发现该IP地址已经被使用，客户机会发出一个DHCP DECLINE数据包给DHCP Server，拒绝此IP地址租约，并重新发送DHCP discover信息。此时，在DHCP服务器管理控制台中，会显示此IP地址为BAD_ADDRESS。

如果网络上没有其它主机使用此IP地址，则客户机的TCP/IP使用租约中提供的IP地址完成初始化，便将收到的IP地址与客户端的网卡绑定。从而可以和其他网络中的主机进行通讯。

- **DHCP****客户机租期续约**

因为客户机申请的IP地址是有一定的时间限制的，DHCP服务器向DHCP客户端分配IP地址称为出租，通常都设置有租借期限,所以在地址到期之前客户机还会向DHCP服务器发送一个续约的请求.

客户机会在租期过去50%的时候，直接向为其提供IP地址的DHCP Server发送DHCP REQUEST消息包。如果客户机接收到该服务器回应的DHCP ACK消息包，客户机就根据包中所提供的新的租期以及其它已经更新的TCP/IP参数，更新自己的配置，IP租用更新完成。如果没有收到该服务器的回复，则客户机继续使用现有的IP地址，因为当前租期还有50%。

如果在租期过去50%的时候没有更新，则客户机将在租期过去87.5%的时候再次向为其提供IP地址的DHCP联系。如果还不成功，到租约的100%时候，客户机必须放弃这个IP地址，重新申请。





## 海量数据处理

hash算法

构建方法:直接寻址法,取摸法,数字分析法,折叠法,平方取中法,平方取中法等

解决冲突的方法:开放地址法,链地址法,再散列法

用途:可以在常数时间内判断元素位置及存在与否.在处理海量数据的时候,使用hash可以快速存取,统计某些数据,将大量的数据进行分类.例如提取某日访问网站次数最多的ip地址等.



位图(bit-map)

排序算法判断集合中是否存在重复数据



布隆过滤器

用于检测一个元素是否属于某个集合,以正确率为前提来换取空间效率和时间效率,只能准确的判断元素不属于集合

布隆过滤器是位数组和hash函数联合使用.布隆过滤器只能插入元素,不能删除元素



倒排索引:按照关键字建立索引,这个索引就被称为倒排索引,被用来全文搜索某个单词在一组文档中的存储位置,它是文档检索系统中最常用的数据结构



外排序:

一般使用归并排序的方式实现

![image-20200802142205350](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200802142205350.png)



堆:

![image-20200802151121204](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200802151121204.png)

利用最大堆来求前n小,最大堆总共就n个元素,然后每来一个,就和顶部当前认为的前n小里面的最大的元素比较,如果比它还小,则替换掉顶部元素,然后再把堆变成大顶堆.



利用大顶堆来做升序排序.首先要将所有的节点都加入,构建成一个大顶堆,建立大顶堆的步骤为:

- 其实堆的存储就是用的数组,**大顶堆：**arr[i] >= arr[2i+1] && arr[i] >= arr[2i+2] 

  **小顶堆：**arr[i] <= arr[2i+1] && arr[i] <= arr[2i+2] 

- 找到最后一个非叶子节点(长度/2-1),比较该节点与它的子节点值,如果小于子节点值就交换.

- 继续找下一个非叶子节点,并判断需不需要交换

- 检查调整后的子树.

- 大顶堆构造完成

怎么进行升序排序呢

- 将跟节点和最后一个节点交换.这样最大的元素就下沉了.
- **将堆排序的过程分成了两部分，构建一个大顶堆，就沉下去最大值，然后断开与最大值的链接，重新构建大顶堆**



桶排序

![image-20200802151608801](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200802151608801.png)



TOP Ｋ问题：

大量数据处理的时候,先使用hash函数将文件分流到不同的机器上,对每台机器再使用hash函数将分流文件拆分成更小的文件.然后建立起hash表,统计出每种词及其词频.hash表建立完成之后,再遍历hash表,遍历过程中使用大小为100的小根堆.





#### [347. 前 K 个高频元素](https://leetcode-cn.com/problems/top-k-frequent-elements/)

![image-20200804210026883](image/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/image-20200804210026883.png)

```java
class Solution {
    public int[] topKFrequent(int[] nums, int k) {
        Map<Integer,Integer> map = new HashMap<>();
        for(int n:nums){
            map.put(n,map.getOrDefault(n,0)+1);
        }

        PriorityQueue<Integer> queue = new PriorityQueue<Integer>((o1,o2)-> map.get(o1)-map.get(o2));

        for(int n:map.keySet()){
            queue.add(n);
            if(queue.size()>k){
                queue.poll();
            }
        }
        int[] res = new int[k];
        int i=1;
        while(queue.size()>0){
            res[k-i] = queue.poll();
            i++;
        }
        return res;

    }
}
```



```java
class Solution {
    public int[] topKFrequent(int[] nums, int k) {
        HashMap<Integer,Integer> maps = new HashMap<>();
        for(int i:nums){
            maps.put(i,maps.getOrDefault(i,0)+1);
        }

        List<Integer>[] list = new List[nums.length+1];
        for(int key : maps.keySet()){
            // 获取出现的次数作为下标
            int i = maps.get(key);
            if(list[i] == null){
               list[i] = new ArrayList();
            } 
            list[i].add(key);
        }
        
        int[] ans = new int[k];
        k--;
        for(int i = nums.length;i>=0;i--){
            if(list[i] != null){
                for(int j = 0;j < list[i].size();j++){
                   if(k < 0)
                        break;
                    ans[k--] = list[i].get(j);
                }
            }

        }
        return ans;

    }
}
```



重复问题:

计算重复的值,首先将大的文件用hash算法分成小的文件,重复的数肯定会在同一个文件中,然后再使用位图来找重复的数.



排序问题,使用位图bit-map





## JVM

Java中关于内存泄漏出现的原因汇总及如何避免内存泄漏（超详细版）https://www.jb51.net/article/92311.htm